# ========================
# DATA CONFIGURATION
# ========================
data:
  target_col: "Churn"
  date_col: "DaySinceLastOrder"
  base_dir: "data"
  raw_path: "data/raw/E Commerce Dataset.xlsx"
  sheet_name: "E Comm"
  processed_dir: "data/processed"
  train_test_dir: "data/train_test"
  test_size: 0.2
  random_state: 42

# ========================
# OPS
# ========================
dataops:
  versions_dir: "artifacts/versions"
  # Business rules validation options
  business_rules:
    # If true, pipeline will raise an error and abort when violations are found
    fail_on_violation: false
    # Persist business rules report into run folder (recommended)
    persist: true
    # Mask PII in persisted report (not implemented fully yet; reserved)
    mask_pii: true

mlops:
  registry_dir: "artifacts/registry"

# ========================
# TRACKING & MONITORING
# ========================
experiments:
  enabled: true
  base_dir: "artifacts/experiments"

monitoring:
  enabled: true
  base_dir: "artifacts/monitoring"
  health_check:
    f1_min: 0.70
    accuracy_min: 0.75
    drift_max: 0.10

explainability:
  enabled: true
  methods: ["shap"]
  shap_samples: 100

# ========================
# PREPROCESSING CONFIG
# ========================
preprocessing:
  clean:
    remove_duplicates: true
    standardize_values: true
  missing_strategy:
    numerical: "median"
    categorical: "mode"
  outlier_method: "iqr"
  outlier_threshold: 1.5
  scaler_type: "standard"
  categorical_encoding: "label"
  create_features: true
  feature_selection: true
  feature_selection_method: "f_classif"
  n_top_features: 15
  use_smote: true
  k_neighbors: 5
  use_tomek: true

# ========================
# MODEL CONFIGURATIONS
# ========================
models:
  logistic_regression:
    C: [0.001, 0.01, 0.1, 1, 10]
    penalty: ["l2"]
    solver: ["lbfgs", "liblinear"]
    max_iter: [1000]

  svm:
    C: [0.1, 1, 10]
    kernel: ["rbf", "linear"]
    gamma: ["scale", "auto"]
    probability: [true]

  decision_tree:
    max_depth: [6, 10, 16, null]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]

  random_forest:
    n_estimators: [50, 100, 200]
    max_depth: [10, 20, null]
    min_samples_split: [2, 5]
    min_samples_leaf: [1, 2]

  xgboost:
    n_estimators: [100, 300, 500]
    max_depth: [3, 5, 7]
    learning_rate: [0.01, 0.05, 0.1]
    eval_metric: ["logloss"]

  adaboost:
    n_estimators: [50, 100]
    learning_rate: [0.01, 0.1, 1.0]

# ========================
# HYPERPARAMETER TUNING
# ========================
tuning:
  method: "randomized"
  cv_folds: 5
  cv_strategy: "stratified"
  n_iter: 20
  scoring: "f1"
  n_jobs: -1

# ========================
# LOGGING (Simplified)
# ========================
logging:
  level: "INFO"
  dir: "artifacts/logs"
  format: "[%(asctime)s] | %(levelname)-7s | %(name)-15s | %(message)s"