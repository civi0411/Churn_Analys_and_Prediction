# Customer Churn Analysis & Prediction

## Overview

Dá»± Ã¡n nÃ y khÃ´ng chá»‰ lÃ  má»™t bÃ i toÃ¡n phÃ¢n loáº¡i Machine Learning thÃ´ng thÆ°á»ng. ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng Software Engineering for Data Science hoÃ n chá»‰nh, giáº£i quyáº¿t bÃ i toÃ¡n dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng rá»i bá» (Customer Churn) cho lÄ©nh vá»±c ThÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ (E-Commerce).

> KhÃ¡c biá»‡t chÃ­nh: Thay vÃ¬ cháº¡y code trÃªn Jupyter Notebook rá»i ráº¡c, há»‡ thá»‘ng nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh má»™t Pipeline khÃ©p kÃ­n, cÃ³ kháº£ nÄƒng tÃ¡i sá»­ dá»¥ng (reproducible), dá»… dÃ ng má»Ÿ rá»™ng (scalable) vÃ  tÃ­ch há»£p sáºµn quy trÃ¬nh MLOps tá»± xÃ¢y dá»±ng (Custom MLOps).

### Business Value

| GiÃ¡ trá»‹ | MÃ´ táº£ |
|---------|-------|
| Screening | Nháº­n diá»‡n khÃ¡ch hÃ ng cÃ³ nguy cÆ¡ rá»i bá» vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao (F1-Score > 0.85) |
| Behavior Insights | Sá»­ dá»¥ng SHAP Ä‘á»ƒ giáº£i thÃ­ch lÃ½ do khÃ¡ch hÃ ng rá»i bá» |
| Cost Optimization | GiÃºp bá»™ pháº­n Marketing khoanh vÃ¹ng Ä‘Ãºng Ä‘á»‘i tÆ°á»£ng Ä‘á»ƒ gá»­i voucher giá»¯ chÃ¢n |
| Model Governance | Version tracking cho dá»¯ liá»‡u, model registry, monitoring vÃ  health check tá»± Ä‘á»™ng |

### Key Technical Features

- Modular Architecture: TÃ¡ch biá»‡t rÃµ rÃ ng giá»¯a Data, Model, Ops, Visualization
- Data Leakage Prevention: Fit trÃªn Train, Transform trÃªn Test - tuÃ¢n thá»§ nghiÃªm ngáº·t
- Multiple Models Support: LogisticRegression, SVM, DecisionTree, RandomForest, XGBoost, AdaBoost
- Automated Hyperparameter Tuning: RandomizedSearchCV vá»›i cross-validation
- Imbalanced Data Handling: SMOTE + Tomek Links Ä‘á»ƒ cÃ¢n báº±ng lá»›p Churn
- Experiment Tracking: LÆ°u trá»¯ tá»«ng run vá»›i snapshot config, metrics, models
- Model Registry: Quáº£n lÃ½ phiÃªn báº£n model production-ready
- Performance Monitoring: Health check tá»± Ä‘á»™ng, drift detection
- Explainability: SHAP values Ä‘á»ƒ giáº£i thÃ­ch quyáº¿t Ä‘á»‹nh cá»§a model

---

## System Architecture

### Pipeline Flow - Luá»“ng xá»­ lÃ½ End-to-End

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#e3f2fd','primaryTextColor':'#1565c0','primaryBorderColor':'#1976d2','lineColor':'#42a5f5','secondaryColor':'#fff3e0','tertiaryColor':'#e8f5e9'}}}%%
flowchart TB
    START(["ğŸ¬ START"])
    FINISH(["âœ¨ FINISH"])
    
    INPUT[("ğŸ“¥ RAW DATA<br/><b>E Commerce Dataset</b><br/>Excel Sheet: E Comm")]
    
    subgraph S1 ["<b>ğŸ“Š STAGE 1: EDA</b>"]
        direction TB
        B1["ğŸ“‚ Load Raw Data"]
        B2["ğŸ” Analyze Missing Values"]
        B3["ğŸ“ˆ Correlation Matrix"]
        B4["ğŸ“Š Distribution Plots"]
        B5["âš ï¸ Outlier Detection"]
        B1 ==> B2 ==> B3 ==> B4 ==> B5
    end

    subgraph S2 ["<b>ğŸ§¹ STAGE 2: PREPROCESSING</b>"]
        direction TB
        C1["ğŸ”§ <b>Clean Data</b><br/>âœ“ Remove duplicates<br/>âœ“ Standardize columns<br/>âœ“ Fix errors"]
        C2["âœ… Validate Quality"]
        C3["âœ‚ï¸ <b>Stratified Split</b><br/>80% Train | 20% Test"]
        C1 ==> C2 ==> C3
    end

    subgraph S3 ["<b>âš™ï¸ STAGE 3: TRANSFORMATION</b>"]
        direction LR
        D1["ğŸ¯ <b>TRAIN SET</b>"]
        D2["ğŸ”¨ <b>FIT + TRANSFORM</b><br/>â€¢ Impute missing<br/>â€¢ Clip outliers<br/>â€¢ Feature engineering<br/>â€¢ Encoding & Scaling"]
        D3{{"ğŸ“¦ <b>LEARNED PARAMS</b><br/>Imputers | Bounds<br/>Encoders | Scaler"}}
        D4["ğŸ§ª <b>TEST SET</b>"]
        D5["ğŸ¨ <b>TRANSFORM ONLY</b><br/>Apply learned params"]
        
        D1 ==> D2
        D2 ==> D3
        D3 -.->|"store"| D2
        D4 ==> D5
        D3 ==>|"apply"| D5
    end

    subgraph S4 ["<b>ğŸ“ STAGE 4: TRAINING</b>"]
        direction TB
        E1["âš–ï¸ <b>Balance Classes</b><br/>SMOTE + Tomek"]
        E2["ğŸ¤– <b>Train 6 Models</b><br/>LR | SVM | DT<br/>RF | XGB | Ada"]
        E3["ğŸ” <b>Hyperparameter Tuning</b><br/>RandomizedSearchCV"]
        E4["ğŸ† <b>Select Best Model</b><br/>Based on F1-Score"]
        E1 ==> E2 ==> E3 ==> E4
    end

    subgraph S5 ["<b>ğŸ“ˆ STAGE 5: EVALUATION</b>"]
        direction TB
        F1["ğŸ“Š Confusion Matrix"]
        F2["ğŸ“‰ ROC-AUC Curves"]
        F3["ğŸ¯ Feature Importance"]
        F4["ğŸ“‹ Model Comparison"]
        F5["ğŸ”¬ SHAP Explainability"]
        F1 ==> F2 ==> F3 ==> F4 ==> F5
    end

    subgraph S6 ["<b>ğŸ“¦ STAGE 6: MLOPS</b>"]
        direction TB
        G1["ğŸ“ Experiment Tracker"]
        G2["ğŸ—ƒï¸ Model Registry"]
        G3["ğŸ”– Data Versioning"]
        G4["ğŸ‘ï¸ Model Monitor"]
        G1 ==> G2 ==> G3 ==> G4
    end

    OUTPUT[("ğŸ’¾ <b>ARTIFACTS</b><br/>experiments/<br/>registry/<br/>monitoring/")]

    START ==> INPUT
    INPUT ==> S1
    S1 ==> S2
    S2 ==> S3
    S3 ==> S4
    S4 ==> S5
    S5 ==> S6
    S6 ==> OUTPUT
    OUTPUT ==> FINISH

    classDef startEnd fill:#4caf50,stroke:#2e7d32,stroke-width:3px,color:#fff,font-weight:bold
    classDef dataNode fill:#2196f3,stroke:#1565c0,stroke-width:3px,color:#fff,font-weight:bold
    classDef stage1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#e65100
    classDef stage2 fill:#e8f5e9,stroke:#43a047,stroke-width:2px,color:#2e7d32
    classDef stage3 fill:#f3e5f5,stroke:#8e24aa,stroke-width:2px,color:#6a1b9a
    classDef stage4 fill:#e0f2f1,stroke:#00897b,stroke-width:2px,color:#00695c
    classDef stage5 fill:#fff8e1,stroke:#fbc02d,stroke-width:2px,color:#f57f17
    classDef stage6 fill:#e8eaf6,stroke:#5e35b1,stroke-width:2px,color:#4527a0
    
    class START,FINISH startEnd
    class INPUT,OUTPUT dataNode
    class S1 stage1
    class S2 stage2
    class S3 stage3
    class S4 stage4
    class S5 stage5
    class S6 stage6
```

### NguyÃªn táº¯c chá»‘ng Data Leakage

> âš ï¸ **QUAN TRá»ŒNG**: Má»i thÃ´ng tin thá»‘ng kÃª (mean, std, IQR bounds, encoding mappings...) chá»‰ Ä‘Æ°á»£c há»c tá»« **Train Set**. Test Set chá»‰ Ä‘Æ°á»£c **Transform** vá»›i tham sá»‘ Ä‘Ã£ há»c - **KHÃ”NG BAO GIá»œ FIT Láº I!**

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#c8e6c9','secondaryColor':'#ffeb3b','tertiaryColor':'#ffcdd2'}}}%%
flowchart LR
    subgraph TRAIN ["<b>ğŸ¯ TRAIN SET</b><br/>(80% data)"]
        direction TB
        A["<b>1ï¸âƒ£ FIT</b><br/>ğŸ“š Learn Parameters<br/>from Training Data"]
        B["<b>2ï¸âƒ£ TRANSFORM</b><br/>ğŸ¨ Apply Parameters<br/>to Training Data"]
        A ===>|"fit"| B
    end

    PARAMS{{"<b>ğŸ“¦ LEARNED PARAMS</b><br/><br/>ğŸ“Š Imputer values<br/>(median/mode)<br/><br/>ğŸ“ Outlier bounds<br/>(Q1-1.5Ã—IQR, Q3+1.5Ã—IQR)<br/><br/>ğŸ”¤ Label encoders<br/>(category â†’ number)<br/><br/>âš–ï¸ Scaler params<br/>(mean, std)<br/><br/>âœ… Feature mask<br/>(selected features)"}}
    
    subgraph TEST ["<b>ğŸ§ª TEST SET</b><br/>(20% data)"]
        direction TB
        D["<b>3ï¸âƒ£ TRANSFORM ONLY</b><br/>ğŸ¨ Apply Parameters<br/>â›” NO FITTING!"]
    end
    
    B ==>|"<b>store</b>"| PARAMS
    PARAMS ==>|"<b>apply frozen</b>"| D
    
    WARNING["âš ï¸ <b>NO DATA LEAKAGE!</b><br/>Test never influences<br/>training parameters"]
    D -.->|"guarantee"| WARNING

    classDef trainStyle fill:#c8e6c9,stroke:#388e3c,stroke-width:3px,color:#1b5e20,font-weight:bold
    classDef paramStyle fill:#fff9c4,stroke:#f9a825,stroke-width:3px,color:#f57f17,font-weight:bold
    classDef testStyle fill:#ffcdd2,stroke:#e53935,stroke-width:3px,color:#c62828,font-weight:bold
    classDef warnStyle fill:#ff5252,stroke:#d32f2f,stroke-width:3px,color:#fff,font-weight:bold
    
    class TRAIN trainStyle
    class PARAMS paramStyle
    class TEST testStyle
    class WARNING warnStyle
```

### Kiáº¿n trÃºc module (Module Architecture)

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'fontSize':'14px'}}}%%
graph TB
    subgraph ENTRY ["<b>ğŸšª ENTRY POINT</b>"]
        MAIN["<b>ğŸ“„ main.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ® CLI Interface<br/>ğŸ“‹ Argument Parser<br/>ğŸš€ Launch Pipeline"]
    end
    
    subgraph PIPELINE ["<b>ğŸ”„ PIPELINE ORCHESTRATOR</b>"]
        PIPE["<b>ğŸ“„ pipeline.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ¬ run_eda()<br/>ğŸ§¹ run_preprocessing()<br/>ğŸ“ run_training()<br/>ğŸ“Š run_visualization()<br/>âš™ï¸ Coordinate all stages"]
    end

    subgraph DATA ["<b>ğŸ“Š DATA MODULE</b><br/>(src/data/)"]
        PREP["<b>preprocessor.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“‚ load_data()<br/>ğŸ§¹ clean_data()<br/>âœ‚ï¸ split_data()"]
        TRANS["<b>transformer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ”¨ fit_transform()<br/>ğŸ¨ transform()<br/>âš–ï¸ get_resampler()"]
    end
    
    subgraph MODELS ["<b>ğŸ¤– MODELS MODULE</b><br/>(src/models/)"]
        TRAIN["<b>trainer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“ train_model()<br/>ğŸ”„ train_all_models()<br/>ğŸ“Š evaluate()"]
        OPT["<b>optimizer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ” optimize_params()<br/>ğŸ¯ grid_search()<br/>ğŸ“ˆ RandomizedSearch"]
        EVAL["<b>evaluator.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š calculate_metrics()<br/>ğŸ“‹ confusion_matrix()<br/>ğŸ“ˆ roc_auc_score()"]
    end
    
    subgraph VIZ ["<b>ğŸ“ˆ VISUALIZATION MODULE</b><br/>(src/visualization/)"]
        EDA["<b>eda_plots.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š missing_values()<br/>ğŸ“‰ correlation_matrix()<br/>ğŸ“ˆ distributions()"]
        EVIZ["<b>evaluate_plots.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š confusion_matrix()<br/>ğŸ“‰ roc_curve()<br/>ğŸ“ˆ feature_importance()"]
    end
    
    subgraph OPS ["<b>âš¡ OPS MODULE</b><br/>(src/ops/)"]
        DOPS["<b>dataops.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>âœ… DataValidator<br/>ğŸ”– DataVersioning<br/>ğŸ” Quality Checks"]
        MOPS["<b>mlops.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“ ExperimentTracker<br/>ğŸ—ƒï¸ ModelRegistry<br/>ğŸ‘ï¸ ModelMonitor<br/>ğŸ”¬ ModelExplainer"]
    end
    
    subgraph UTILS ["<b>ğŸ› ï¸ UTILITIES</b><br/>(src/)"]
        UTIL["<b>utils.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>âš™ï¸ ConfigLoader<br/>ğŸ“ Logger<br/>ğŸ’¾ IOHandler<br/>ğŸ² set_random_seed()"]
    end

    MAIN ==>|"execute"| PIPE
    PIPE ==>|"orchestrate"| DATA
    PIPE ==>|"orchestrate"| MODELS
    PIPE ==>|"orchestrate"| VIZ
    PIPE ==>|"orchestrate"| OPS
    
    DATA -->|"use"| UTIL
    MODELS -->|"use"| UTIL
    VIZ -->|"use"| UTIL
    OPS -->|"use"| UTIL
    
    PREP -.->|"feeds into"| TRANS
    TRAIN -.->|"uses"| OPT
    TRAIN -.->|"uses"| EVAL

    classDef entryStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#0d47a1
    classDef pipeStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px,color:#4a148c
    classDef dataStyle fill:#e8f5e9,stroke:#388e3c,stroke-width:3px,color:#1b5e20
    classDef modelStyle fill:#fff3e0,stroke:#f57c00,stroke-width:3px,color:#e65100
    classDef vizStyle fill:#fce4ec,stroke:#c2185b,stroke-width:3px,color:#880e4f
    classDef opsStyle fill:#fff8e1,stroke:#fbc02d,stroke-width:3px,color:#f57f17
    classDef utilStyle fill:#eceff1,stroke:#546e7a,stroke-width:3px,color:#263238
    
    class ENTRY entryStyle
    class PIPELINE pipeStyle
    class DATA dataStyle
    class MODELS modelStyle
    class VIZ vizStyle
    class OPS opsStyle
    class UTILS utilStyle
```

---

## ğŸ“‚ Project Structure

```text
Churn_Analys_and_Prediction/
â”‚
â”œâ”€â”€ ğŸ“„ .gitignore                        # ğŸš« Git ignore rules
â”œâ”€â”€ ğŸ“„ main.py                           # ğŸšª Entry point chÃ­nh - CLI interface
â”œâ”€â”€ ğŸ“„ README.md                         # ğŸ“– Project documentation
â”œâ”€â”€ ğŸ“„ requirements.txt                  # ğŸ“¦ Python dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ config/                           # âš™ï¸ Cáº¤U HÃŒNH
â”‚   â””â”€â”€ ğŸ“„ config.yaml                   # File cáº¥u hÃ¬nh táº­p trung (paths, models, params)
â”‚
â”œâ”€â”€ ğŸ“‚ notebook/                         # ğŸ““ JUPYTER NOTEBOOKS
â”‚   â””â”€â”€ ğŸ“„ demo_pipeline.ipynb           # Demo luá»“ng cháº¡y cá»§a pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ src/                              # ğŸ’» MÃƒ NGUá»’N CHÃNH
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ pipeline.py                   # ğŸ”„ Orchestrator - Ä‘iá»u phá»‘i toÃ n bá»™ pipeline
â”‚   â”œâ”€â”€ ğŸ“„ utils.py                      # ğŸ› ï¸ Utilities (Logger, IO, ConfigLoader)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ data/                         # ğŸ“Š DATA PROCESSING MODULE
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ preprocessor.py           # Giai Ä‘oáº¡n 1: Load, Clean, Split (Stateless)
â”‚   â”‚   â””â”€â”€ ğŸ“„ transformer.py            # Giai Ä‘oáº¡n 2: Transform, Feature Eng (Stateful)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/                       # ğŸ¤– MODEL TRAINING MODULE
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ trainer.py                # Train logic, model selection
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ optimizer.py              # Hyperparameter tuning
â”‚   â”‚   â””â”€â”€ ğŸ“„ evaluator.py              # Metrics calculation logic
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ ops/                          # âš¡ MLOPS & DATAOPS MODULE
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ dataops/                  # Data Operations
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ drift_detector.py     # PhÃ¡t hiá»‡n trÃ´i dáº¡t dá»¯ liá»‡u (Data Drift)
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ validator.py          # Kiá»ƒm tra cháº¥t lÆ°á»£ng dá»¯ liá»‡u (Schema/Values)
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ versioning.py         # Quáº£n lÃ½ phiÃªn báº£n dá»¯ liá»‡u
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ mlops/                    # ML Operations
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ explainer.py          # Model Interpretability (SHAP/LIME)
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ monitoring.py         # Theo dÃµi hiá»‡u nÄƒng model
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ registry.py           # Quáº£n lÃ½, lÆ°u/táº£i model artifacts
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ tracking.py           # Experiment tracking
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“‚ report/                   # Reporting
â”‚   â”‚       â””â”€â”€ ğŸ“„ generator.py          # Sinh bÃ¡o cÃ¡o tá»± Ä‘á»™ng
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ visualization/                # ğŸ“ˆ VISUALIZATION MODULE
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ eda_plots.py              # Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch khÃ¡m phÃ¡ (EDA)
â”‚       â””â”€â”€ ğŸ“„ evaluate_plots.py         # Biá»ƒu Ä‘á»“ Ä‘Ã¡nh giÃ¡ model (ROC, Confusion Matrix)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                             # ğŸ’¾ Dá»® LIá»†U (LOCAL WORKSPACE)
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                          # Dá»¯ liá»‡u thÃ´ gá»‘c
â”‚   â”œâ”€â”€ ğŸ“‚ processed/                    # Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch
â”‚   â””â”€â”€ ğŸ“‚ train_test/                   # Dá»¯ liá»‡u Ä‘Ã£ split/transform Ä‘á»ƒ train
â”‚
â”œâ”€â”€ ğŸ“‚ artifacts/                        # ğŸ—„ï¸ OUTPUTS & ARCHIVE (Generated at runtime)
â”‚   â”œâ”€â”€ ğŸ“‚ experiments/                  # Logs chi tiáº¿t tá»«ng láº§n cháº¡y
â”‚   â”œâ”€â”€ ğŸ“‚ model_registry/               # CÃ¡c model Ä‘Ã£ Ä‘Ã³ng gÃ³i cho production
â”‚   â”œâ”€â”€ ğŸ“‚ monitoring/                   # Logs giÃ¡m sÃ¡t hiá»‡u nÄƒng
â”‚   â”œâ”€â”€ ğŸ“‚ versions/                     # Metadata cÃ¡c phiÃªn báº£n dá»¯ liá»‡u
â”‚   â”œâ”€â”€ ğŸ“‚ figures/                      # HÃ¬nh áº£nh biá»ƒu Ä‘á»“ má»›i nháº¥t
â”‚   â””â”€â”€ ğŸ“‚ logs/                         # System logs
â”‚
â””â”€â”€ ğŸ“‚ tests/                            # ğŸ§ª TESTING SUITE (Pytest)
    â”œâ”€â”€ ğŸ“„ conftest.py                   # Fixtures config
    â”œâ”€â”€ ğŸ“„ test_pipeline.py              # Integration tests
    â”œâ”€â”€ ğŸ“„ test_utils.py                 # Unit tests cho utils
    â”œâ”€â”€ ğŸ“‚ test_data/                    # Tests cho data processing
    â”œâ”€â”€ ğŸ“‚ test_models/                  # Tests cho model logic
    â”œâ”€â”€ ğŸ“‚ test_ops/                     # Tests cho MLOps/DataOps components
    â””â”€â”€ ğŸ“‚ test_visualization/           # Tests cho plotting functions
```


## âš™ï¸ Cáº¥u hÃ¬nh há»‡ thá»‘ng (Configuration)

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c táº­p trung trong `config/config.yaml`. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c sections chÃ­nh:

### ğŸ“Š Data Configuration
```yaml
data:
  target_col: "Churn"                              # Cá»™t target cáº§n dá»± Ä‘oÃ¡n
  date_col: "DaySinceLastOrder"                    # Cá»™t ngÃ y thÃ¡ng (náº¿u cÃ³)
  raw_path: "data/raw/E Commerce Dataset.xlsx"     # ÄÆ°á»ng dáº«n file input
  sheet_name: "E Comm"                             # TÃªn sheet Excel
  test_size: 0.2                                   # Tá»· lá»‡ test set (20%)
  random_state: 42                                 # Seed cho reproducibility
```

### ğŸ”§ Preprocessing Configuration
```yaml
preprocessing:
  clean:
    remove_duplicates: true                        # Loáº¡i bá» dÃ²ng trÃ¹ng láº·p
    standardize_values: true                       # Chuáº©n hÃ³a giÃ¡ trá»‹ (lowercase, strip...)
  
  missing_strategy:
    numerical: "median"                            # Äiá»n giÃ¡ trá»‹ khuyáº¿t: median cho sá»‘
    categorical: "mode"                            # Äiá»n giÃ¡ trá»‹ khuyáº¿t: mode cho categorical
  
  outlier_method: "iqr"                           # PhÆ°Æ¡ng phÃ¡p xá»­ lÃ½ outliers: IQR
  outlier_threshold: 1.5                          # NgÆ°á»¡ng IQR (Q1-1.5*IQR, Q3+1.5*IQR)
  
  scaler_type: "standard"                         # Loáº¡i scaler: standard, minmax, robust
  categorical_encoding: "label"                   # Encoding: label, onehot
  
  create_features: true                           # Táº¡o features má»›i
  feature_selection: true                         # Lá»c features quan trá»ng
  feature_selection_method: "f_classif"           # PhÆ°Æ¡ng phÃ¡p: f_classif, mutual_info
  n_top_features: 15                              # Sá»‘ features giá»¯ láº¡i
  
  use_smote: true                                 # Sá»­ dá»¥ng SMOTE Ä‘á»ƒ balance classes
  k_neighbors: 5                                  # Sá»‘ neighbors cho SMOTE
  use_tomek: true                                 # Káº¿t há»£p Tomek Links (clean boundaries)
```

### ğŸ¤– Models Configuration
```yaml
models:
  logistic_regression:
    C: [0.001, 0.01, 0.1, 1, 10]
    penalty: ["l2"]
    solver: ["lbfgs", "liblinear"]
    max_iter: [1000]

  random_forest:
    n_estimators: [50, 100, 200]
    max_depth: [10, 20, null]
    min_samples_split: [2, 5]
    min_samples_leaf: [1, 2]

  xgboost:
    n_estimators: [100, 300, 500]
    max_depth: [3, 5, 7]
    learning_rate: [0.01, 0.05, 0.1]
    eval_metric: ["logloss"]
```

### ğŸ” Tuning Configuration
```yaml
tuning:
  method: "randomized"                            # PhÆ°Æ¡ng phÃ¡p: grid, randomized
  cv_folds: 5                                     # Sá»‘ folds cho cross-validation
  cv_strategy: "stratified"                       # Stratified Ä‘á»ƒ giá»¯ tá»· lá»‡ classes
  n_iter: 20                                      # Sá»‘ iterations cho RandomizedSearch
  scoring: "f1"                                   # Metric chÃ­nh Ä‘á»ƒ optimize
  n_jobs: -1                                      # Sá»­ dá»¥ng táº¥t cáº£ CPU cores
```

### ğŸ“¦ MLOps Configuration
```yaml
experiments:
  enabled: true
  base_dir: "artifacts/experiments"
  experiments_file: "experiments.csv"

mlops:
  registry_dir: "artifacts/model_registry"

monitoring:
  enabled: true
  base_dir: "artifacts/monitoring"
  performance_log: "performance_log.csv"
  health_check:
    f1_min: 0.70                                  # F1 tá»‘i thiá»ƒu cháº¥p nháº­n Ä‘Æ°á»£c
    accuracy_min: 0.75                            # Accuracy tá»‘i thiá»ƒu
    drift_max: 0.10                               # Drift tá»‘i Ä‘a cho phÃ©p (10%)

explainability:
  enabled: true
  methods: ["shap"]
  shap_samples: 100                               # Sá»‘ samples dÃ¹ng cho SHAP
```

---

## ğŸš€ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  sá»­ dá»¥ng (Installation & Usage)

### ğŸ“¥ BÆ°á»›c 1: Clone Repository

```powershell
git clone https://github.com/civi0411/Churn_Analys_and_Prediction.git
cd Churn_Analys_and_Prediction
```

### ğŸ BÆ°á»›c 2: Táº¡o Virtual Environment (Khuyáº¿n nghá»‹)

**Windows (PowerShell):**
```powershell
# Táº¡o virtual environment
python -m venv .venv

# KÃ­ch hoáº¡t virtual environment
.\.venv\Scripts\Activate.ps1

# Náº¿u gáº·p lá»—i ExecutionPolicy:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

**Linux/MacOS:**
```bash
# Táº¡o virtual environment
python3 -m venv .venv

# KÃ­ch hoáº¡t
source .venv/bin/activate
```

### ğŸ“¦ BÆ°á»›c 3: CÃ i Ä‘áº·t Dependencies

```powershell
# Upgrade pip
python -m pip install --upgrade pip

# CÃ i Ä‘áº·t táº¥t cáº£ packages
pip install -r requirements.txt

# Kiá»ƒm tra cÃ i Ä‘áº·t thÃ nh cÃ´ng
pip list
```

#### ğŸ“‹ Dependencies chi tiáº¿t (requirements.txt)

```
# --- Core Data Science (Xá»­ lÃ½ dá»¯ liá»‡u ná»n táº£ng) ---
numpy>=1.24.3           # TÃ­nh toÃ¡n ma tráº­n, sá»‘ há»c
pandas>=2.0.3           # Xá»­ lÃ½ DataFrame (Tá»‘i Æ°u bá»™ nhá»›)
scipy>=1.11.0           # Thá»‘ng kÃª khoa há»c (DÃ¹ng cho Drift Detection)
openpyxl>=3.1.2         # Engine Ä‘á»c file Excel (.xlsx)
pyarrow>=10.0.0         # Backend xá»­ lÃ½ dá»¯ liá»‡u lá»›n (Báº¯t buá»™c cho Parquet)
fastparquet>=2023.10.1  # Engine Ä‘á»c/ghi file Parquet tá»‘i Æ°u

# --- Machine Learning Models ---
scikit-learn>=1.3.0     # ThÆ° viá»‡n ML chÃ­nh (Pipeline, Metrics, RF)
xgboost>=2.0.0          # Model Gradient Boosting (Máº¡nh máº½)
imbalanced-learn>=0.11.0 # Há»— trá»£ SMOTE (Xá»­ lÃ½ dá»¯ liá»‡u máº¥t cÃ¢n báº±ng)

# --- Visualization (Trá»±c quan hÃ³a) ---
matplotlib>=3.7.2       # Váº½ biá»ƒu Ä‘á»“ cÆ¡ báº£n
seaborn>=0.12.2         # Váº½ biá»ƒu Ä‘á»“ thá»‘ng kÃª Ä‘áº¹p

# --- Explainability (Giáº£i thÃ­ch mÃ´ hÃ¬nh) ---
shap>=0.42.1            # Giáº£i thÃ­ch lÃ½ do Churn (Feature Importance)

# --- Utilities & System (Cáº¥u hÃ¬nh & Há»‡ thá»‘ng) ---
PyYAML>=6.0.1           # Äá»c file cáº¥u hÃ¬nh config.yaml
joblib>=1.3.2           # LÆ°u/Táº£i model (.pkl) tá»‘c Ä‘á»™ cao
tqdm>=4.66.1            # Thanh tiáº¿n trÃ¬nh (Loading bar)
typing-extensions>=4.7.1 # Há»— trá»£ Type Hinting

# --- Testing ---
pytest>=8.0.0           # Framework kiá»ƒm thá»­ (Testing framework)
pytest-cov>=6.0.0       # BÃ¡o cÃ¡o Ä‘á»™ bao phá»§ code (Coverage reporting)
```

### âš™ï¸ BÆ°á»›c 4: Cáº¥u hÃ¬nh (Optional)

Chá»‰nh sá»­a `config/config.yaml` náº¿u cáº§n:
```yaml
# Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n data
data:
  raw_path: "data/raw/your_data.xlsx"
  sheet_name: "YourSheet"

# Äiá»u chá»‰nh tham sá»‘ models
models:
  xgboost:
    n_estimators: [100, 200]  # Giáº£m Ä‘á»ƒ cháº¡y nhanh hÆ¡n
    max_depth: [3, 5]            # Thay vÃ¬ [3, 5, 7]
```

---

## ğŸ¯ CÃ¡ch cháº¡y Pipeline (Running the Pipeline)
#### ğŸ–¥ï¸ CLI Arguments (HÆ°á»›ng dáº«n cháº¡y dÃ²ng lá»‡nh)

Script `main.py` há»— trá»£ cÃ¡c tham sá»‘ sau Ä‘á»ƒ Ä‘iá»u khiá»ƒn luá»“ng cháº¡y cá»§a pipeline:

| Tham sá»‘ | Kiá»ƒu | Máº·c Ä‘á»‹nh | TÃ¹y chá»n (Choices) | MÃ´ táº£ chi tiáº¿t |
| :--- | :---: | :---: | :--- | :--- |
| **`--mode`** | `str` | `full` | `full`, `preprocess`, `train`, `eda`, `visualize`, `predict` | Cháº¿ Ä‘á»™ váº­n hÃ nh cá»§a Pipeline:<br>â€¢ `full`: Cháº¡y toÃ n bá»™ (Data -> Train -> Eval)<br>â€¢ `eda`: PhÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u<br>â€¢ `predict`: Dá»± Ä‘oÃ¡n trÃªn dá»¯ liá»‡u má»›i |
| **`--data`** | `str` | *Config* | *ÄÆ°á»ng dáº«n file* | ÄÆ°á»ng dáº«n file dá»¯ liá»‡u Ä‘áº§u vÃ o (Ghi Ä‘Ã¨ cáº¥u hÃ¬nh trong `config.yaml`).<br>Há»— trá»£ Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i hoáº·c tÆ°Æ¡ng Ä‘á»‘i. |
| **`--model`** | `str` | `all` | *TÃªn model* | Chá»‰ Ä‘á»‹nh model cá»¥ thá»ƒ Ä‘á»ƒ huáº¥n luyá»‡n/dá»± Ä‘oÃ¡n (VÃ­ dá»¥: `xgboost`, `random_forest`). |
| **`--optimize`** | `flag` | `False` | *(KhÃ´ng cÃ³)* | ThÃªm cá» nÃ y Ä‘á»ƒ báº­t cháº¿ Ä‘á»™ **Hyperparameter Tuning** (Tinh chá»‰nh tham sá»‘ mÃ´ hÃ¬nh). |
| **`--config`** | `str` | `config.yaml` | *ÄÆ°á»ng dáº«n file* | ÄÆ°á»ng dáº«n Ä‘áº¿n file cáº¥u hÃ¬nh tÃ¹y chá»‰nh (náº¿u cáº§n). |

### ğŸ’¡ Usage Examples (VÃ­ dá»¥)
**Mode: EDA (Exploratory Data Analysis)**

```powershell
# PhÃ¢n tÃ­ch dá»¯ liá»‡u thÃ´, táº¡o cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan.
python main.py --mode eda
```
**Mode: Preprocess (Data Preprocessing)**

```powershell
# LÃ m sáº¡ch, split vÃ  transform dá»¯ liá»‡u.
python main.py --mode preprocess
```
 **Mode: Train (Model Training)**
```powershell
## Train má»™t model cá»¥ thá»ƒ (khÃ´ng optimize)
python main.py --mode train --model 

# Train má»™t model vá»›i hyperparameter tuning
python main.py --mode train --model xgboost --optimize

# Train táº¥t cáº£ models
python main.py --mode train --model all

# Train táº¥t cáº£ models + optimize
python main.py --mode train --model all --optimize
```
  **Mode: Visualize (Evaluation)**
```powershell
# Cháº¡y quick training (khÃ´ng optimize) vÃ  táº¡o visualizations.
python main.py --mode visualize --model xgboost
```
**Mode: Full (End-to-End Pipeline)** â­ Khuyáº¿n nghá»‹

```powershell
# Full pipeline vá»›i model cá»¥ thá»ƒ + optimize
python main.py --mode full --model xgboost --optimize

# Full pipeline vá»›i táº¥t cáº£ models + optimize
python main.py --mode full --model all --optimize

# Full pipeline nhanh (khÃ´ng optimize)
python main.py --mode full --model xgboost
```

## ğŸ§ª Testing (Kiá»ƒm thá»­)

### ğŸ“Š Cáº¥u trÃºc Tests

Tests Ä‘Æ°á»£c tá»• chá»©c theo cáº¥u trÃºc module tÆ°Æ¡ng á»©ng vá»›i `src/`:

```powershell
tests/
â”œâ”€â”€ conftest.py                    # Pytest fixtures chung
â”œâ”€â”€ test_utils.py                  # Tests cho src/utils.py
â”œâ”€â”€ test_pipeline.py               # Tests cho src/pipeline.py
â”œâ”€â”€ test_data/
â”œâ”€â”€ test_models/
â”œâ”€â”€ test_ops/
â”‚   â”œâ”€â”€ test_dataops/           # DataValidator, DataVersioning
â”‚   â””â”€â”€ test_mlops/              # ExperimentTracker, ModelRegistry, ModelMonitor
â”œâ”€â”€ test_visualization/
```

### ğŸƒ CÃ¡ch cháº¡y Tests

```powershell
# Cháº¡y táº¥t cáº£ tests
pytest

# Cháº¡y module cá»¥ thá»ƒ
pytest tests/test_data/ -v                  # Data module
pytest tests/test_models/ -v                # Models module

# Cháº¡y file cá»¥ thá»ƒ
pytest tests/test_data/test_preprocessor.py -v

# Cháº¡y test case cá»¥ thá»ƒ
pytest tests/test_data/test_preprocessor.py::TestDataPreprocessor::test_clean_data -v
```


## ğŸ”® Dá»± Ä‘oÃ¡n vá»›i dá»¯ liá»‡u má»›i (Prediction/Inference)

### 6ï¸âƒ£ **Mode: Predict (Dá»± Ä‘oÃ¡n trÃªn dá»¯ liá»‡u má»›i)**

Chá»©c nÄƒng nÃ y cho phÃ©p báº¡n sá»­ dá»¥ng model Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ dá»± Ä‘oÃ¡n trÃªn **dá»¯ liá»‡u má»›i** (chÆ°a tá»«ng train/test).

```powershell
python main.py --mode predict --data "data/raw/your_new_data.xlsx"
```

**Tham sá»‘:**
- `--data`: ÄÆ°á»ng dáº«n file dá»¯ liá»‡u Ä‘áº§u vÃ o (csv/xlsx/parquet). NÃªn lÃ  dá»¯ liá»‡u má»›i hoáº·c máº«u cáº§n inference.
- (TÃ¹y chá»n) `--model`: TÃªn model cá»¥ thá»ƒ náº¿u muá»‘n chá»‰ Ä‘á»‹nh (máº·c Ä‘á»‹nh: model production má»›i nháº¥t).

**Output:**
- File káº¿t quáº£ dá»± Ä‘oÃ¡n sáº½ Ä‘Æ°á»£c lÆ°u táº¡i: `artifacts/predictions/<ten_file>_predicted.csv`
- Trong file káº¿t quáº£ sáº½ cÃ³ thÃªm cá»™t `prediction` (label dá»± Ä‘oÃ¡n) vÃ  `probability` (náº¿u model há»— trá»£).

**Best Practice:**
- **NÃªn** dÃ¹ng dá»¯ liá»‡u má»›i (chÆ°a tá»«ng train/test) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a model.
- **KhÃ´ng nÃªn** dÃ¹ng láº¡i dá»¯ liá»‡u Ä‘Ã£ train/test Ä‘á»ƒ trÃ¡nh data leakage.
- CÃ³ thá»ƒ dÃ¹ng sample nhá» Ä‘á»ƒ kiá»ƒm thá»­ ká»¹ thuáº­t, nhÆ°ng nÃªn lÃ  sample tá»« dá»¯ liá»‡u má»›i.

**Troubleshooting:**
- Náº¿u gáº·p lá»—i vá» cá»™t thiáº¿u, hÃ£y Ä‘áº£m báº£o file input cÃ³ Ä‘á»§ cÃ¡c cá»™t nhÆ° lÃºc train (trá»« cá»™t target).
- Náº¿u model khÃ´ng há»— trá»£ predict_proba, file output sáº½ chá»‰ cÃ³ cá»™t `prediction`.
- Náº¿u khÃ´ng tÃ¬m tháº¥y model, kiá»ƒm tra láº¡i thÆ° má»¥c `artifacts/model_registry/`.

**VÃ­ dá»¥:**
```powershell
# Dá»± Ä‘oÃ¡n trÃªn file Excel má»›i
python main.py --mode predict --data "data/raw/customer_batch_2025.xlsx"

# Dá»± Ä‘oÃ¡n trÃªn file CSV
python main.py --mode predict --data "data/raw/new_customers.csv"

# Káº¿t quáº£ sáº½ náº±m á»Ÿ: artifacts/predictions/customer_batch_2025_predicted.csv
```
