# ğŸ”„ Customer Churn Analysis & Prediction

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-orange.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-2.0+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ Tá»•ng quan (Overview)

Dá»± Ã¡n nÃ y khÃ´ng chá»‰ lÃ  má»™t bÃ i toÃ¡n phÃ¢n loáº¡i Machine Learning thÃ´ng thÆ°á»ng. ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng **Software Engineering for Data Science** hoÃ n chá»‰nh, giáº£i quyáº¿t bÃ i toÃ¡n dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng rá»i bá» (Customer Churn) cho lÄ©nh vá»±c ThÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ (E-Commerce).

> ğŸ’¡ KhÃ¡c vá»›i viá»‡c cháº¡y code trÃªn Jupyter Notebook rá»i ráº¡c, há»‡ thá»‘ng nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh má»™t **Pipeline khÃ©p kÃ­n**, cÃ³ kháº£ nÄƒng tÃ¡i sá»­ dá»¥ng (reproducible), dá»… dÃ ng má»Ÿ rá»™ng (scalable) vÃ  tÃ­ch há»£p sáºµn quy trÃ¬nh **MLOps tá»± xÃ¢y dá»±ng** (Custom MLOps).

### ğŸ’¼ GiÃ¡ Trá»‹ Kinh Doanh (Business Value)

| GiÃ¡ trá»‹ | MÃ´ táº£ |
|---------|-------|
| ğŸ¯ **SÃ ng lá»c sá»›m** | Nháº­n diá»‡n khÃ¡ch hÃ ng cÃ³ nguy cÆ¡ rá»i bá» vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao (F1-Score > 0.90) |
| ğŸ” **Hiá»ƒu hÃ nh vi** | Sá»­ dá»¥ng SHAP Ä‘á»ƒ giáº£i thÃ­ch lÃ½ do khÃ¡ch hÃ ng rá»i bá» (VD: Do thá»i gian giao hÃ ng, hay do Ã­t nháº­n Ä‘Æ°á»£c Æ°u Ä‘Ã£i) |
| ğŸ’° **Tá»‘i Æ°u chi phÃ­** | GiÃºp bá»™ pháº­n Marketing khoanh vÃ¹ng Ä‘Ãºng Ä‘á»‘i tÆ°á»£ng Ä‘á»ƒ gá»­i voucher giá»¯ chÃ¢n, trÃ¡nh lÃ£ng phÃ­ ngÃ¢n sÃ¡ch |

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng (System Architecture)

### Pipeline Flow

```mermaid
flowchart TB
    subgraph INPUT["ğŸ“¥ INPUT"]
        A[("RAW DATA<br/>Excel/CSV")]
    end

    subgraph STAGE1["ğŸ“Š STAGE 1: EDA"]
        B["Load & Inspect<br/>â€¢ Missing value analysis<br/>â€¢ Correlation heatmaps<br/>â€¢ Distribution plots"]
    end

    subgraph STAGE2["ğŸ§¹ STAGE 2: CLEANING"]
        C["Clean Data<br/>â€¢ Remove duplicates<br/>â€¢ Standardize categories<br/>â€¢ Basic validation"]
    end

    subgraph STAGE3["âœ‚ï¸ STAGE 3: SPLIT"]
        D["Stratified Split<br/>80% Train / 20% Test"]
        E["TRAIN SET"]
        F["TEST SET"]
    end

    subgraph STAGE4["âš™ï¸ STAGE 4: TRANSFORM"]
        G["FIT on Train<br/>â€¢ Imputation<br/>â€¢ Outlier clipping<br/>â€¢ Feature engineering<br/>â€¢ Encoding<br/>â€¢ Scaling"]
        H[("LEARNED PARAMS<br/>Scaler, Imputer,<br/>Encoder, Bounds")]
        I["PROCESSED<br/>TRAIN"]
        J["TRANSFORM<br/>TEST"]
    end

    subgraph STAGE5["ğŸ“ STAGE 5: TRAINING"]
        K["Model Training<br/>â€¢ SMOTE injection<br/>â€¢ Multiple models<br/>â€¢ Hyperparameter tuning<br/>â€¢ Cross-validation"]
        L["BEST MODEL<br/>RF / XGBoost / LR"]
    end

    subgraph STAGE6["ğŸ“ˆ STAGE 6: EVALUATION"]
        M["Evaluation<br/>â€¢ Confusion matrix<br/>â€¢ ROC-AUC curves<br/>â€¢ Feature importance<br/>â€¢ SHAP explainability"]
    end

    subgraph STAGE7["ğŸ“¦ STAGE 7: REGISTRY"]
        N["Model Registry<br/>â€¢ Save best model<br/>â€¢ Version tracking<br/>â€¢ Metadata logging"]
    end

    subgraph STAGE8["ğŸ‘ï¸ STAGE 8: MONITORING"]
        O["Monitoring<br/>â€¢ Performance logging<br/>â€¢ Drift detection<br/>â€¢ Health checks"]
    end

    A --> B --> C --> D
    D --> E & F
    E --> G
    G --> H
    H --> I
    H -.->|"Apply learned params"| J
    F --> J
    I & J --> K --> L --> M --> N --> O

    style INPUT fill:#e1f5fe
    style STAGE1 fill:#fff3e0
    style STAGE2 fill:#e8f5e9
    style STAGE3 fill:#fce4ec
    style STAGE4 fill:#f3e5f5
    style STAGE5 fill:#e0f2f1
    style STAGE6 fill:#fff8e1
    style STAGE7 fill:#e8eaf6
    style STAGE8 fill:#fbe9e7
```

### ğŸ” Key Principle: NO DATA LEAKAGE

```mermaid
flowchart LR
    subgraph TRAIN["ğŸ¯ TRAIN SET"]
        A["FIT + TRANSFORM"]
    end

    subgraph PARAMS["ğŸ“Š LEARNED PARAMS"]
        B["Scaler params<br/>Imputer values<br/>Encoder mappings<br/>IQR bounds"]
    end
    
    subgraph TEST["ğŸ§ª TEST SET"]
        C["TRANSFORM ONLY"]
    end
    
    A -->|"Learn"| B
    B -->|"Apply"| C

    style TRAIN fill:#c8e6c9
    style PARAMS fill:#fff9c4
    style TEST fill:#ffcdd2
```

---

## ğŸ§© Logic xá»­ lÃ½ (Logical Components)

```mermaid
graph TB
    subgraph PREPROCESSING["ğŸ”§ Preprocessing Module"]
        P1["DataCleaner"]
        P2["FeatureEngineer"]
        P3["Encoder"]
        P4["Scaler"]
        P5["FeatureSelector"]
    end
    
    subgraph MODELING["ğŸ¤– Modeling Module"]
        M1["BaseModel"]
        M2["RandomForest"]
        M3["XGBoost"]
        M4["LogisticRegression"]
        M5["HyperparamTuner"]
    end
    
    subgraph OPS["âš¡ MLOps Module"]
        O1["ExperimentTracker"]
        O2["ModelRegistry"]
        O3["PerformanceMonitor"]
        O4["AlertSystem"]
    end
    
    subgraph UTILS["ğŸ› ï¸ Utilities"]
        U1["ConfigLoader"]
        U2["Logger"]
        U3["DataIO"]
    end
    
    PREPROCESSING --> MODELING
    MODELING --> OPS
    UTILS -.->|"Support"| PREPROCESSING
    UTILS -.->|"Support"| MODELING
    UTILS -.->|"Support"| OPS
```

---

## ğŸ“ Project Structure

```
ğŸ“¦ Churn_Analysis_and_Predict/
â”œâ”€â”€ ğŸ“‚ config/
â”‚   â””â”€â”€ ğŸ“„ config.yaml                    # Central configuration file
â”‚
â”œâ”€â”€ ğŸ“‚ src/                               # Source code modules
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ utils.py                       # Logging, IO, config handling
â”‚   â”œâ”€â”€ ğŸ“„ preprocessing.py               # Data preprocessing pipeline
â”‚   â”œâ”€â”€ ğŸ“„ modeling.py                    # Model training & evaluation
â”‚   â”œâ”€â”€ ğŸ“„ visualization.py               # Plotting & visualization
â”‚   â”œâ”€â”€ ğŸ“„ ops.py                         # MLOps: tracking, registry, monitoring
â”‚   â””â”€â”€ ğŸ“„ pipeline.py                    # Main pipeline orchestrator
â”‚
â”œâ”€â”€ ğŸ“‚ data/                              # [WORKSPACE] Latest working files
â”‚   â”œâ”€â”€ ğŸ“‚ raw/
â”‚   â”‚   â””â”€â”€ ğŸ“„ E_Commerce.xlsx            # Raw input data
â”‚   â”œâ”€â”€ ğŸ“‚ processed/
â”‚   â”‚   â””â”€â”€ ğŸ“„ E_Commerce_cleaned.parquet # Cleaned data
â”‚   â””â”€â”€ ğŸ“‚ train_test/
â”‚       â”œâ”€â”€ ğŸ“„ E_Commerce_train.parquet   # Latest train split
â”‚       â””â”€â”€ ğŸ“„ E_Commerce_test.parquet    # Latest test split
â”‚
â”œâ”€â”€ ğŸ“‚ artifacts/                         # [ARCHIVE] Historical results
â”‚   â”œâ”€â”€ ğŸ“‚ experiments/                   # Run-specific snapshots
â”‚   â”‚   â””â”€â”€ ğŸ“‚ 20251205_203000_FULL/      # Example run ID
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ config_snapshot.yaml
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ params.json
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ metrics.json
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ run.log
â”‚   â”‚       â”œâ”€â”€ ğŸ“‚ figures/
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“‚ eda/
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“‚ evaluation/
â”‚   â”‚       â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“„ preprocessor.joblib
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“„ xgboost.joblib
â”‚   â”‚       â””â”€â”€ ğŸ“‚ data/
â”‚   â”‚           â”œâ”€â”€ ğŸ“„ processed.parquet
â”‚   â”‚           â”œâ”€â”€ ğŸ“„ train.parquet
â”‚   â”‚           â””â”€â”€ ğŸ“„ test.parquet
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ model_registry/                # Production models
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ registry.json
â”‚   â”‚   â””â”€â”€ ğŸ“„ xgboost_v1_20251205.joblib
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ versions/                      # Data lineage tracking
â”‚   â”‚   â””â”€â”€ ğŸ“„ versions.json
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ monitoring/                    # Model monitoring data
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ performance_log.csv
â”‚   â”‚   â””â”€â”€ ğŸ“„ alerts_log.csv
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ logs/
â”‚       â””â”€â”€ ğŸ“„ MAIN_20251205.log
â”‚
â”œâ”€â”€ ğŸ“„ main.py                            # CLI entry point
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
â””â”€â”€ ğŸ“„ README.md                          # This file
```

---

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng (Usage Instructions)

### 1ï¸âƒ£ Clone repository

```bash
git clone https://github.com/civi0411/Churn_Analysis_and_Predict.git
cd Churn_Analysis_and_Predict
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure settings

Edit `config/config.yaml` to set paths, model parameters, etc.

### 5ï¸âƒ£ Usage Modes

#### ğŸ”„ Full Pipeline (Recommended)

Tá»± Ä‘á»™ng thá»±c hiá»‡n: Clean â†’ Split â†’ Train â†’ Optimize â†’ Visualize â†’ Save Artifacts

```bash
python main.py --mode full --model xgboost --optimize
```

#### ğŸ”§ Step-by-Step Execution

```bash
# Exploratory Data Analysis
python main.py --mode eda

# Preprocessing
python main.py --mode preprocess

# Train specific model
python main.py --mode train --model xgboost

# Full pipeline with all models
python main.py --mode full

# Visualization only
python main.py --mode visualize
```

### 6ï¸âƒ£ Cháº¡y kiá»ƒm thá»­ (Testing)

```bash
# Cháº¡y toÃ n bá»™ test
pytest

# Cháº¡y riÃªng pháº§n Unit Test (Test hÃ m láº»)
pytest tests/test_module

# Cháº¡y riÃªng pháº§n Integration Test (Test luá»“ng)
pytest tests/test_flow
```

---

## ğŸ“Š Model Comparison

```mermaid
xychart-beta
    title "Model Performance Comparison"
    x-axis ["Random Forest", "XGBoost", "Logistic Reg"]
    y-axis "Score" 0 --> 1
    bar [0.89, 0.92, 0.85]
    line [0.87, 0.90, 0.83]
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  Made with â¤ï¸ by <a href="https://github.com/civi0411">civi0411</a>
</p>

