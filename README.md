# ğŸ”„ Customer Churn Analysis & Prediction

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-orange.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-2.0+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ Tá»•ng quan (Overview)

Dá»± Ã¡n nÃ y khÃ´ng chá»‰ lÃ  má»™t bÃ i toÃ¡n phÃ¢n loáº¡i Machine Learning thÃ´ng thÆ°á»ng. ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng **Software Engineering for Data Science** hoÃ n chá»‰nh, giáº£i quyáº¿t bÃ i toÃ¡n dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng rá»i bá» (Customer Churn) cho lÄ©nh vá»±c ThÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ (E-Commerce).

> ğŸ’¡ **KhÃ¡c biá»‡t chÃ­nh**: Thay vÃ¬ cháº¡y code trÃªn Jupyter Notebook rá»i ráº¡c, há»‡ thá»‘ng nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh má»™t **Pipeline khÃ©p kÃ­n**, cÃ³ kháº£ nÄƒng tÃ¡i sá»­ dá»¥ng (reproducible), dá»… dÃ ng má»Ÿ rá»™ng (scalable) vÃ  tÃ­ch há»£p sáºµn quy trÃ¬nh **MLOps tá»± xÃ¢y dá»±ng** (Custom MLOps).

### ğŸ’¼ GiÃ¡ Trá»‹ Kinh Doanh (Business Value)

| GiÃ¡ trá»‹ | MÃ´ táº£ |
|---------|-------|
| ğŸ¯ **SÃ ng lá»c sá»›m** | Nháº­n diá»‡n khÃ¡ch hÃ ng cÃ³ nguy cÆ¡ rá»i bá» vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao (F1-Score > 0.85) |
| ğŸ” **Hiá»ƒu hÃ nh vi** | Sá»­ dá»¥ng SHAP Ä‘á»ƒ giáº£i thÃ­ch lÃ½ do khÃ¡ch hÃ ng rá»i bá» (VD: Do thá»i gian giao hÃ ng, hay do Ã­t nháº­n Ä‘Æ°á»£c Æ°u Ä‘Ã£i) |
| ğŸ’° **Tá»‘i Æ°u chi phÃ­** | GiÃºp bá»™ pháº­n Marketing khoanh vÃ¹ng Ä‘Ãºng Ä‘á»‘i tÆ°á»£ng Ä‘á»ƒ gá»­i voucher giá»¯ chÃ¢n, trÃ¡nh lÃ£ng phÃ­ ngÃ¢n sÃ¡ch |
| ğŸ“¦ **Quáº£n trá»‹ mÃ´ hÃ¬nh** | Version tracking cho dá»¯ liá»‡u, model registry, monitoring vÃ  health check tá»± Ä‘á»™ng |

### ğŸ“ Äáº·c Ä‘iá»ƒm ká»¹ thuáº­t ná»•i báº­t

- âœ… **Modular Architecture**: TÃ¡ch biá»‡t rÃµ rÃ ng giá»¯a Data, Model, Ops, Visualization
- âœ… **Data Leakage Prevention**: Fit trÃªn Train, Transform trÃªn Test - tuÃ¢n thá»§ nghiÃªm ngáº·t
- âœ… **Multiple Models Support**: LogisticRegression, SVM, DecisionTree, RandomForest, XGBoost, AdaBoost
- âœ… **Automated Hyperparameter Tuning**: RandomizedSearchCV vá»›i cross-validation
- âœ… **Imbalanced Data Handling**: SMOTE + Tomek Links Ä‘á»ƒ cÃ¢n báº±ng lá»›p Churn
- âœ… **Experiment Tracking**: LÆ°u trá»¯ tá»«ng run vá»›i snapshot config, metrics, models
- âœ… **Model Registry**: Quáº£n lÃ½ phiÃªn báº£n model production-ready
- âœ… **Performance Monitoring**: Health check tá»± Ä‘á»™ng, drift detection
- âœ… **Explainability**: SHAP values Ä‘á»ƒ giáº£i thÃ­ch quyáº¿t Ä‘á»‹nh cá»§a model

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng (System Architecture)

### ğŸ“Š Pipeline Flow - Luá»“ng xá»­ lÃ½ End-to-End

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#e3f2fd','primaryTextColor':'#1565c0','primaryBorderColor':'#1976d2','lineColor':'#42a5f5','secondaryColor':'#fff3e0','tertiaryColor':'#e8f5e9'}}}%%
flowchart TB
    START(["ğŸ¬ START"])
    FINISH(["âœ¨ FINISH"])
    
    INPUT[("ğŸ“¥ RAW DATA<br/><b>E Commerce Dataset</b><br/>Excel Sheet: E Comm")]
    
    subgraph S1 ["<b>ğŸ“Š STAGE 1: EDA</b>"]
        direction TB
        B1["ğŸ“‚ Load Raw Data"]
        B2["ğŸ” Analyze Missing Values"]
        B3["ğŸ“ˆ Correlation Matrix"]
        B4["ğŸ“Š Distribution Plots"]
        B5["âš ï¸ Outlier Detection"]
        B1 ==> B2 ==> B3 ==> B4 ==> B5
    end

    subgraph S2 ["<b>ğŸ§¹ STAGE 2: PREPROCESSING</b>"]
        direction TB
        C1["ğŸ”§ <b>Clean Data</b><br/>âœ“ Remove duplicates<br/>âœ“ Standardize columns<br/>âœ“ Fix errors"]
        C2["âœ… Validate Quality"]
        C3["âœ‚ï¸ <b>Stratified Split</b><br/>80% Train | 20% Test"]
        C1 ==> C2 ==> C3
    end

    subgraph S3 ["<b>âš™ï¸ STAGE 3: TRANSFORMATION</b>"]
        direction LR
        D1["ğŸ¯ <b>TRAIN SET</b>"]
        D2["ğŸ”¨ <b>FIT + TRANSFORM</b><br/>â€¢ Impute missing<br/>â€¢ Clip outliers<br/>â€¢ Feature engineering<br/>â€¢ Encoding & Scaling"]
        D3{{"ğŸ“¦ <b>LEARNED PARAMS</b><br/>Imputers | Bounds<br/>Encoders | Scaler"}}
        D4["ğŸ§ª <b>TEST SET</b>"]
        D5["ğŸ¨ <b>TRANSFORM ONLY</b><br/>Apply learned params"]
        
        D1 ==> D2
        D2 ==> D3
        D3 -.->|"store"| D2
        D4 ==> D5
        D3 ==>|"apply"| D5
    end

    subgraph S4 ["<b>ğŸ“ STAGE 4: TRAINING</b>"]
        direction TB
        E1["âš–ï¸ <b>Balance Classes</b><br/>SMOTE + Tomek"]
        E2["ğŸ¤– <b>Train 6 Models</b><br/>LR | SVM | DT<br/>RF | XGB | Ada"]
        E3["ğŸ” <b>Hyperparameter Tuning</b><br/>RandomizedSearchCV"]
        E4["ğŸ† <b>Select Best Model</b><br/>Based on F1-Score"]
        E1 ==> E2 ==> E3 ==> E4
    end

    subgraph S5 ["<b>ğŸ“ˆ STAGE 5: EVALUATION</b>"]
        direction TB
        F1["ğŸ“Š Confusion Matrix"]
        F2["ğŸ“‰ ROC-AUC Curves"]
        F3["ğŸ¯ Feature Importance"]
        F4["ğŸ“‹ Model Comparison"]
        F5["ğŸ”¬ SHAP Explainability"]
        F1 ==> F2 ==> F3 ==> F4 ==> F5
    end

    subgraph S6 ["<b>ğŸ“¦ STAGE 6: MLOPS</b>"]
        direction TB
        G1["ğŸ“ Experiment Tracker"]
        G2["ğŸ—ƒï¸ Model Registry"]
        G3["ğŸ”– Data Versioning"]
        G4["ğŸ‘ï¸ Model Monitor"]
        G1 ==> G2 ==> G3 ==> G4
    end

    OUTPUT[("ğŸ’¾ <b>ARTIFACTS</b><br/>experiments/<br/>registry/<br/>monitoring/")]

    START ==> INPUT
    INPUT ==> S1
    S1 ==> S2
    S2 ==> S3
    S3 ==> S4
    S4 ==> S5
    S5 ==> S6
    S6 ==> OUTPUT
    OUTPUT ==> FINISH

    classDef startEnd fill:#4caf50,stroke:#2e7d32,stroke-width:3px,color:#fff,font-weight:bold
    classDef dataNode fill:#2196f3,stroke:#1565c0,stroke-width:3px,color:#fff,font-weight:bold
    classDef stage1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#e65100
    classDef stage2 fill:#e8f5e9,stroke:#43a047,stroke-width:2px,color:#2e7d32
    classDef stage3 fill:#f3e5f5,stroke:#8e24aa,stroke-width:2px,color:#6a1b9a
    classDef stage4 fill:#e0f2f1,stroke:#00897b,stroke-width:2px,color:#00695c
    classDef stage5 fill:#fff8e1,stroke:#fbc02d,stroke-width:2px,color:#f57f17
    classDef stage6 fill:#e8eaf6,stroke:#5e35b1,stroke-width:2px,color:#4527a0
    
    class START,FINISH startEnd
    class INPUT,OUTPUT dataNode
    class S1 stage1
    class S2 stage2
    class S3 stage3
    class S4 stage4
    class S5 stage5
    class S6 stage6
```

### ğŸ” NguyÃªn táº¯c chá»‘ng Data Leakage

> âš ï¸ **QUAN TRá»ŒNG**: Má»i thÃ´ng tin thá»‘ng kÃª (mean, std, IQR bounds, encoding mappings...) chá»‰ Ä‘Æ°á»£c há»c tá»« **Train Set**. Test Set chá»‰ Ä‘Æ°á»£c **Transform** vá»›i tham sá»‘ Ä‘Ã£ há»c - **KHÃ”NG BAO GIá»œ FIT Láº I!**

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#c8e6c9','secondaryColor':'#ffeb3b','tertiaryColor':'#ffcdd2'}}}%%
flowchart LR
    subgraph TRAIN ["<b>ğŸ¯ TRAIN SET</b><br/>(80% data)"]
        direction TB
        A["<b>1ï¸âƒ£ FIT</b><br/>ğŸ“š Learn Parameters<br/>from Training Data"]
        B["<b>2ï¸âƒ£ TRANSFORM</b><br/>ğŸ¨ Apply Parameters<br/>to Training Data"]
        A ===>|"fit"| B
    end

    PARAMS{{"<b>ğŸ“¦ LEARNED PARAMS</b><br/><br/>ğŸ“Š Imputer values<br/>(median/mode)<br/><br/>ğŸ“ Outlier bounds<br/>(Q1-1.5Ã—IQR, Q3+1.5Ã—IQR)<br/><br/>ğŸ”¤ Label encoders<br/>(category â†’ number)<br/><br/>âš–ï¸ Scaler params<br/>(mean, std)<br/><br/>âœ… Feature mask<br/>(selected features)"}}
    
    subgraph TEST ["<b>ğŸ§ª TEST SET</b><br/>(20% data)"]
        direction TB
        D["<b>3ï¸âƒ£ TRANSFORM ONLY</b><br/>ğŸ¨ Apply Parameters<br/>â›” NO FITTING!"]
    end
    
    B ==>|"<b>store</b>"| PARAMS
    PARAMS ==>|"<b>apply frozen</b>"| D
    
    WARNING["âš ï¸ <b>NO DATA LEAKAGE!</b><br/>Test never influences<br/>training parameters"]
    D -.->|"guarantee"| WARNING

    classDef trainStyle fill:#c8e6c9,stroke:#388e3c,stroke-width:3px,color:#1b5e20,font-weight:bold
    classDef paramStyle fill:#fff9c4,stroke:#f9a825,stroke-width:3px,color:#f57f17,font-weight:bold
    classDef testStyle fill:#ffcdd2,stroke:#e53935,stroke-width:3px,color:#c62828,font-weight:bold
    classDef warnStyle fill:#ff5252,stroke:#d32f2f,stroke-width:3px,color:#fff,font-weight:bold
    
    class TRAIN trainStyle
    class PARAMS paramStyle
    class TEST testStyle
    class WARNING warnStyle
```

### ğŸ§© Kiáº¿n trÃºc module (Module Architecture)

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'fontSize':'14px'}}}%%
graph TB
    subgraph ENTRY ["<b>ğŸšª ENTRY POINT</b>"]
        MAIN["<b>ğŸ“„ main.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ® CLI Interface<br/>ğŸ“‹ Argument Parser<br/>ğŸš€ Launch Pipeline"]
    end
    
    subgraph PIPELINE ["<b>ğŸ”„ PIPELINE ORCHESTRATOR</b>"]
        PIPE["<b>ğŸ“„ pipeline.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ¬ run_eda()<br/>ğŸ§¹ run_preprocessing()<br/>ğŸ“ run_training()<br/>ğŸ“Š run_visualization()<br/>âš™ï¸ Coordinate all stages"]
    end

    subgraph DATA ["<b>ğŸ“Š DATA MODULE</b><br/>(src/data/)"]
        PREP["<b>preprocessor.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“‚ load_data()<br/>ğŸ§¹ clean_data()<br/>âœ‚ï¸ split_data()"]
        TRANS["<b>transformer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ”¨ fit_transform()<br/>ğŸ¨ transform()<br/>âš–ï¸ get_resampler()"]
    end
    
    subgraph MODELS ["<b>ğŸ¤– MODELS MODULE</b><br/>(src/models/)"]
        TRAIN["<b>trainer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“ train_model()<br/>ğŸ”„ train_all_models()<br/>ğŸ“Š evaluate()"]
        OPT["<b>optimizer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ” optimize_params()<br/>ğŸ¯ grid_search()<br/>ğŸ“ˆ RandomizedSearch"]
        EVAL["<b>evaluator.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š calculate_metrics()<br/>ğŸ“‹ confusion_matrix()<br/>ğŸ“ˆ roc_auc_score()"]
    end
    
    subgraph VIZ ["<b>ğŸ“ˆ VISUALIZATION MODULE</b><br/>(src/visualization/)"]
        EDA["<b>eda_plots.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š missing_values()<br/>ğŸ“‰ correlation_matrix()<br/>ğŸ“ˆ distributions()"]
        EVIZ["<b>evaluate_plots.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š confusion_matrix()<br/>ğŸ“‰ roc_curve()<br/>ğŸ“ˆ feature_importance()"]
    end
    
    subgraph OPS ["<b>âš¡ OPS MODULE</b><br/>(src/ops/)"]
        DOPS["<b>dataops.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>âœ… DataValidator<br/>ğŸ”– DataVersioning<br/>ğŸ” Quality Checks"]
        MOPS["<b>mlops.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“ ExperimentTracker<br/>ğŸ—ƒï¸ ModelRegistry<br/>ğŸ‘ï¸ ModelMonitor<br/>ğŸ”¬ ModelExplainer"]
    end
    
    subgraph UTILS ["<b>ğŸ› ï¸ UTILITIES</b><br/>(src/)"]
        UTIL["<b>utils.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>âš™ï¸ ConfigLoader<br/>ğŸ“ Logger<br/>ğŸ’¾ IOHandler<br/>ğŸ² set_random_seed()"]
    end

    MAIN ==>|"execute"| PIPE
    PIPE ==>|"orchestrate"| DATA
    PIPE ==>|"orchestrate"| MODELS
    PIPE ==>|"orchestrate"| VIZ
    PIPE ==>|"orchestrate"| OPS
    
    DATA -->|"use"| UTIL
    MODELS -->|"use"| UTIL
    VIZ -->|"use"| UTIL
    OPS -->|"use"| UTIL
    
    PREP -.->|"feeds into"| TRANS
    TRAIN -.->|"uses"| OPT
    TRAIN -.->|"uses"| EVAL

    classDef entryStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#0d47a1
    classDef pipeStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px,color:#4a148c
    classDef dataStyle fill:#e8f5e9,stroke:#388e3c,stroke-width:3px,color:#1b5e20
    classDef modelStyle fill:#fff3e0,stroke:#f57c00,stroke-width:3px,color:#e65100
    classDef vizStyle fill:#fce4ec,stroke:#c2185b,stroke-width:3px,color:#880e4f
    classDef opsStyle fill:#fff8e1,stroke:#fbc02d,stroke-width:3px,color:#f57f17
    classDef utilStyle fill:#eceff1,stroke:#546e7a,stroke-width:3px,color:#263238
    
    class ENTRY entryStyle
    class PIPELINE pipeStyle
    class DATA dataStyle
    class MODELS modelStyle
    class VIZ vizStyle
    class OPS opsStyle
    class UTILS utilStyle
```

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c (Project Structure)

```
ğŸ“¦ Churn_Analys_and_Prediction/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                           # ğŸšª Entry point chÃ­nh - CLI interface
â”œâ”€â”€ ğŸ“„ README.md                         # ğŸ“– Documentation (file nÃ y)
â”œâ”€â”€ ğŸ“„ requirements.txt                  # ğŸ“¦ Python dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ config/                           # âš™ï¸ Cáº¤U HÃŒNH
â”‚   â””â”€â”€ ğŸ“„ config.yaml                   # File cáº¥u hÃ¬nh táº­p trung (paths, models, tuning params)
â”‚
â”œâ”€â”€ ğŸ“‚ src/                              # ğŸ’» MÃƒ NGUá»’N CHÃNH
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ pipeline.py                   # ğŸ”„ Orchestrator - Ä‘iá»u phá»‘i toÃ n bá»™ pipeline
â”‚   â”œâ”€â”€ ğŸ“„ utils.py                      # ğŸ› ï¸ Tiá»‡n Ã­ch: Logger, IOHandler, ConfigLoader
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ data/                         # ğŸ“Š MODULE Xá»¬ LÃ Dá»® LIá»†U
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ preprocessor.py           # Giai Ä‘oáº¡n 1: Load, Clean, Split (Stateless)
â”‚   â”‚   â””â”€â”€ ğŸ“„ transformer.py            # Giai Ä‘oáº¡n 2: Transform, Feature Engineering (Stateful)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/                       # ğŸ¤– MODULE MÃ” HÃŒNH
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ trainer.py                # Train models, evaluate, select best
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ optimizer.py              # Hyperparameter tuning (RandomizedSearch)
â”‚   â”‚   â””â”€â”€ ğŸ“„ evaluator.py              # Metrics calculation, evaluation logic
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ ops/                          # âš¡ MODULE MLOPS
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ dataops.py                # DataValidator, DataVersioning
â”‚   â”‚   â””â”€â”€ ğŸ“„ mlops.py                  # ExperimentTracker, ModelRegistry, Monitor, Explainer
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ visualization/                # ğŸ“ˆ MODULE VISUALIZATION
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ eda_plots.py              # EDA visualizations (missing, correlation, distribution)
â”‚       â””â”€â”€ ğŸ“„ evaluate_plots.py         # Model evaluation plots (confusion matrix, ROC, feature importance)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                             # ğŸ’¾ Dá»® LIá»†U LÃ€M VIá»†C (WORKSPACE)
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                          # Dá»¯ liá»‡u thÃ´ gá»‘c
â”‚   â”‚   â””â”€â”€ ğŸ“„ E Commerce Dataset.xlsx   # File Excel input chÃ­nh
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ processed/                    # Dá»¯ liá»‡u Ä‘Ã£ clean (intermediate)
â”‚   â”‚   â””â”€â”€ ğŸ“„ E Commerce Dataset_cleaned.parquet
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ train_test/                   # Dá»¯ liá»‡u Ä‘Ã£ split vÃ  transform (ready for training)
â”‚       â”œâ”€â”€ ğŸ“„ E Commerce Dataset_train.parquet
â”‚       â””â”€â”€ ğŸ“„ E Commerce Dataset_test.parquet
â”‚
â”œâ”€â”€ ğŸ“‚ artifacts/                        # ğŸ—„ï¸ OUTPUTS & ARCHIVE
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ experiments/                  # ğŸ”¬ EXPERIMENT TRACKING
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ experiments.csv           # Master log cá»§a táº¥t cáº£ runs
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“‚ <run_id>/                 # VD: 20251207_153322_FULL/
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ config_snapshot.yaml  # Snapshot cáº¥u hÃ¬nh cá»§a run nÃ y
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ params.json           # Hyperparameters Ä‘Ã£ sá»­ dá»¥ng
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ metrics.json          # Káº¿t quáº£ metrics (F1, AUC, Precision, Recall...)
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ run.log               # Log chi tiáº¿t cá»§a run
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ ğŸ“‚ data/                 # Data snapshots
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“„ train.parquet     # Train set Ä‘Ã£ transform
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“„ test.parquet      # Test set Ä‘Ã£ transform
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ ğŸ“‚ models/               # Models artifacts
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“„ transformer.joblib    # DataTransformer (cáº§n cho inference!)
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“„ xgboost.joblib        # Best model cá»§a run
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ ğŸ“‚ figures/              # Visualizations
â”‚   â”‚           â”œâ”€â”€ ğŸ“‚ eda/              # EDA plots (missing, correlation, distribution)
â”‚   â”‚           â”‚   â”œâ”€â”€ ğŸ“„ missing_values.png
â”‚   â”‚           â”‚   â”œâ”€â”€ ğŸ“„ correlation_matrix.png
â”‚   â”‚           â”‚   â””â”€â”€ ğŸ“„ numerical_distributions.png
â”‚   â”‚           â”‚
â”‚   â”‚           â””â”€â”€ ğŸ“‚ evaluation/       # Model evaluation plots
â”‚   â”‚               â”œâ”€â”€ ğŸ“„ confusion_matrix_xgboost.png
â”‚   â”‚               â”œâ”€â”€ ğŸ“„ roc_curve.png
â”‚   â”‚               â”œâ”€â”€ ğŸ“„ feature_importance.png
â”‚   â”‚               â”œâ”€â”€ ğŸ“„ model_comparison.png
â”‚   â”‚               â””â”€â”€ ğŸ“„ shap_summary.png
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ model_registry/               # ğŸ“¦ MODEL REGISTRY (Production Models)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ registry.json             # Metadata: model versions, metrics, run_id
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ xgboost_v1_20251207_154104.joblib
â”‚   â”‚   â””â”€â”€ ğŸ“„ xgboost_v2_20251207_160224.joblib
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ monitoring/                   # ğŸ‘ï¸ MODEL MONITORING
â”‚   â”‚   â””â”€â”€ ğŸ“„ performance_log.csv       # Log hiá»‡u nÄƒng theo thá»i gian (tracking drift, degradation)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ versions/                     # ğŸ”– DATA VERSIONING
â”‚   â”‚   â””â”€â”€ ğŸ“„ versions.json             # Hash vÃ  metadata cá»§a cÃ¡c phiÃªn báº£n dá»¯ liá»‡u
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ figures/                      # ğŸ“Š Latest figures (symbolic links hoáº·c copy)
â”‚   â””â”€â”€ ğŸ“‚ logs/                         # ğŸ“ Global logs
â”‚       â””â”€â”€ ğŸ“„ MAIN_20251207.log
â”‚
â””â”€â”€ ğŸ“‚ tests/                            # ğŸ§ª TESTING SUITE
    â”œâ”€â”€ ğŸ“„ conftest.py                   # Pytest fixtures vÃ  configuration
    â”œâ”€â”€ ğŸ“„ test_utils.py                 # Tests cho src/utils.py
    â”œâ”€â”€ ğŸ“„ test_pipeline.py              # Tests cho src/pipeline.py
    â”‚
    â”œâ”€â”€ ğŸ“‚ test_data/                    # Tests cho src/data/
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ“„ test_preprocessor.py      # Tests cho DataPreprocessor
    â”‚   â””â”€â”€ ğŸ“„ test_transformer.py       # Tests cho DataTransformer
    â”‚
    â”œâ”€â”€ ğŸ“‚ test_models/                  # Tests cho src/models/
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ“„ test_trainer.py           # Tests cho ModelTrainer
    â”‚   â”œâ”€â”€ ğŸ“„ test_optimizer.py         # Tests cho ModelOptimizer
    â”‚   â””â”€â”€ ğŸ“„ test_evaluator.py         # Tests cho ModelEvaluator
    â”‚
    â”œâ”€â”€ ğŸ“‚ test_ops/                     # Tests cho src/ops/
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ“„ test_dataops.py           # Tests cho DataValidator, DataVersioning
    â”‚   â””â”€â”€ ğŸ“„ test_mlops.py             # Tests cho ExperimentTracker, ModelRegistry, etc.
    â”‚
    â”œâ”€â”€ ğŸ“‚ test_visualization/           # Tests cho src/visualization/
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ“„ test_eda_plots.py         # Tests cho EDAVisualizer
    â”‚   â””â”€â”€ ğŸ“„ test_evaluate_plots.py    # Tests cho EvaluateVisualizer
    â”‚
    â””â”€â”€ ğŸ“‚ data/                         # Test data samples
        â”œâ”€â”€ ğŸ“„ sample_raw.csv            # Raw data máº«u cho testing
        â””â”€â”€ ğŸ“„ sample_processed.csv      # Processed data máº«u
```

### ğŸ“‹ Giáº£i thÃ­ch cÃ¡c thÃ nh pháº§n quan trá»ng

| ThÆ° má»¥c/File | Má»¥c Ä‘Ã­ch | Khi nÃ o cáº§n |
|--------------|----------|-------------|
| `config/config.yaml` | Cáº¥u hÃ¬nh táº­p trung cho toÃ n bá»™ pipeline | Thay Ä‘á»•i paths, model params, tuning settings |
| `src/pipeline.py` | Orchestrator Ä‘iá»u phá»‘i cÃ¡c stages | Entry point logic cho cÃ¡c modes (eda, train, full...) |
| `src/data/preprocessor.py` | Clean vÃ  split data (stateless) | Xá»­ lÃ½ dá»¯ liá»‡u thÃ´ ban Ä‘áº§u |
| `src/data/transformer.py` | Feature engineering (stateful) | Há»c tham sá»‘ tá»« train, apply cho test |
| `src/models/trainer.py` | Training logic | Train vÃ  evaluate models |
| `src/ops/mlops.py` | MLOps components | Tracking, registry, monitoring |
| `artifacts/experiments/` | LÆ°u trá»¯ tá»«ng run | Review láº¡i experiments cÅ© |
| `artifacts/model_registry/` | Models production-ready | Deploy model vÃ o production |
| `artifacts/monitoring/` | Performance logs | Theo dÃµi model degradation |
| `tests/` | Unit & integration tests (77 tests) | CI/CD, Ä‘áº£m báº£o code quality |

---

## âš™ï¸ Cáº¥u hÃ¬nh há»‡ thá»‘ng (Configuration)

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c táº­p trung trong `config/config.yaml`. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c sections chÃ­nh:

### ğŸ“Š Data Configuration
```yaml
data:
  target_col: "Churn"                              # Cá»™t target cáº§n dá»± Ä‘oÃ¡n
  date_col: "DaySinceLastOrder"                    # Cá»™t ngÃ y thÃ¡ng (náº¿u cÃ³)
  raw_path: "data/raw/E Commerce Dataset.xlsx"     # ÄÆ°á»ng dáº«n file input
  sheet_name: "E Comm"                             # TÃªn sheet Excel
  batch_folder: "data/raw"                         # ThÆ° má»¥c chá»©a nhiá»u files (batch processing)
  test_size: 0.2                                   # Tá»· lá»‡ test set (20%)
  random_state: 42                                 # Seed cho reproducibility
```

### ğŸ”§ Preprocessing Configuration
```yaml
preprocessing:
  clean:
    remove_duplicates: true                        # Loáº¡i bá» dÃ²ng trÃ¹ng láº·p
    standardize_values: true                       # Chuáº©n hÃ³a giÃ¡ trá»‹ (lowercase, strip...)
  
  missing_strategy:
    numerical: "median"                            # Äiá»n giÃ¡ trá»‹ khuyáº¿t: median cho sá»‘
    categorical: "mode"                            # Äiá»n giÃ¡ trá»‹ khuyáº¿t: mode cho categorical
  
  outlier_method: "iqr"                           # PhÆ°Æ¡ng phÃ¡p xá»­ lÃ½ outliers: IQR
  outlier_threshold: 1.5                          # NgÆ°á»¡ng IQR (Q1-1.5*IQR, Q3+1.5*IQR)
  
  scaler_type: "standard"                         # Loáº¡i scaler: standard, minmax, robust
  categorical_encoding: "label"                   # Encoding: label, onehot
  
  create_features: true                           # Táº¡o features má»›i
  feature_selection: true                         # Lá»c features quan trá»ng
  feature_selection_method: "f_classif"           # PhÆ°Æ¡ng phÃ¡p: f_classif, mutual_info
  n_top_features: 15                              # Sá»‘ features giá»¯ láº¡i
  
  use_smote: true                                 # Sá»­ dá»¥ng SMOTE Ä‘á»ƒ balance classes
  k_neighbors: 5                                  # Sá»‘ neighbors cho SMOTE
  use_tomek: true                                 # Káº¿t há»£p Tomek Links (clean boundaries)
```

### ğŸ¤– Models Configuration
```yaml
models:
  logistic_regression:
    C: [0.001, 0.01, 0.1, 1, 10]
    penalty: ["l2"]
    solver: ["lbfgs", "liblinear"]
    max_iter: [1000]

  random_forest:
    n_estimators: [50, 100, 200]
    max_depth: [10, 20, null]
    min_samples_split: [2, 5]
    min_samples_leaf: [1, 2]

  xgboost:
    n_estimators: [100, 300, 500]
    max_depth: [3, 5, 7]
    learning_rate: [0.01, 0.05, 0.1]
    eval_metric: ["logloss"]
```

### ğŸ” Tuning Configuration
```yaml
tuning:
  method: "randomized"                            # PhÆ°Æ¡ng phÃ¡p: grid, randomized
  cv_folds: 5                                     # Sá»‘ folds cho cross-validation
  cv_strategy: "stratified"                       # Stratified Ä‘á»ƒ giá»¯ tá»· lá»‡ classes
  n_iter: 20                                      # Sá»‘ iterations cho RandomizedSearch
  scoring: "f1"                                   # Metric chÃ­nh Ä‘á»ƒ optimize
  n_jobs: -1                                      # Sá»­ dá»¥ng táº¥t cáº£ CPU cores
```

### ğŸ“¦ MLOps Configuration
```yaml
experiments:
  enabled: true
  base_dir: "artifacts/experiments"
  experiments_file: "experiments.csv"

mlops:
  registry_dir: "artifacts/model_registry"

monitoring:
  enabled: true
  base_dir: "artifacts/monitoring"
  performance_log: "performance_log.csv"
  health_check:
    f1_min: 0.70                                  # F1 tá»‘i thiá»ƒu cháº¥p nháº­n Ä‘Æ°á»£c
    accuracy_min: 0.75                            # Accuracy tá»‘i thiá»ƒu
    drift_max: 0.10                               # Drift tá»‘i Ä‘a cho phÃ©p (10%)

explainability:
  enabled: true
  methods: ["shap"]
  shap_samples: 100                               # Sá»‘ samples dÃ¹ng cho SHAP
```

---

## ğŸš€ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  sá»­ dá»¥ng (Installation & Usage)

### ğŸ“¥ BÆ°á»›c 1: Clone Repository

```powershell
git clone https://github.com/civi0411/Churn_Analys_and_Prediction.git
cd Churn_Analys_and_Prediction
```

### ğŸ BÆ°á»›c 2: Táº¡o Virtual Environment (Khuyáº¿n nghá»‹)

**Windows (PowerShell):**
```powershell
# Táº¡o virtual environment
python -m venv .venv

# KÃ­ch hoáº¡t virtual environment
.\.venv\Scripts\Activate.ps1

# Náº¿u gáº·p lá»—i ExecutionPolicy:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

**Linux/MacOS:**
```bash
# Táº¡o virtual environment
python3 -m venv .venv

# KÃ­ch hoáº¡t
source .venv/bin/activate
```

### ğŸ“¦ BÆ°á»›c 3: CÃ i Ä‘áº·t Dependencies

```powershell
# Upgrade pip
python -m pip install --upgrade pip

# CÃ i Ä‘áº·t táº¥t cáº£ packages
pip install -r requirements.txt

# Kiá»ƒm tra cÃ i Ä‘áº·t thÃ nh cÃ´ng
pip list
```

#### ğŸ“‹ Dependencies chi tiáº¿t (requirements.txt)

**1. Core Data Science (Xá»­ lÃ½ dá»¯ liá»‡u ná»n táº£ng)**
```
numpy>=1.24.3           # TÃ­nh toÃ¡n ma tráº­n, sá»‘ há»c
pandas>=2.0.3           # Xá»­ lÃ½ DataFrame (Báº£n 2.0+ tá»‘i Æ°u bá»™ nhá»›)
openpyxl>=3.1.2         # Báº®T BUá»˜C: Engine Ä‘á»ƒ Ä‘á»c file Excel (.xlsx)
```

**2. Machine Learning Models**
```
scikit-learn>=1.3.0     # ThÆ° viá»‡n ML chÃ­nh (Pipeline, Metrics, RF...)
xgboost>=2.0.0          # Model Gradient Boosting (Máº¡nh máº½ hÆ¡n RF)
imbalanced-learn>=0.11.0 # Há»— trá»£ SMOTE (Xá»­ lÃ½ dá»¯ liá»‡u máº¥t cÃ¢n báº±ng)
```

**3. Visualization (Trá»±c quan hÃ³a)**
```
matplotlib>=3.7.2       # Váº½ biá»ƒu Ä‘á»“ cÆ¡ báº£n
seaborn>=0.12.2         # Váº½ biá»ƒu Ä‘á»“ thá»‘ng kÃª Ä‘áº¹p (Heatmap, Distribution)
```

**4. Explainability (Giáº£i thÃ­ch mÃ´ hÃ¬nh)**
```
shap>=0.42.1            # Giáº£i thÃ­ch lÃ½ do táº¡i sao khÃ¡ch hÃ ng Churn (Feature Importance)
```

**5. Utilities & System (Cáº¥u hÃ¬nh & Há»‡ thá»‘ng)**
```
PyYAML>=6.0.1           # Äá»c file cáº¥u hÃ¬nh config.yaml
joblib>=1.3.2           # LÆ°u/Táº£i model (.pkl) tá»‘c Ä‘á»™ cao
tqdm>=4.66.1            # Thanh tiáº¿n trÃ¬nh (Loading bar) cho training
typing-extensions>=4.7.1 # Há»— trá»£ Type Hinting
```

**6. Testing**
```
pytest>=9.0.0           # Testing framework
pytest-cov>=7.0.0       # Coverage reporting
```

> ğŸ’¡ **LÆ°u Ã½**: Tá»•ng dung lÆ°á»£ng download ~500MB. Thá»i gian cÃ i Ä‘áº·t ~5-10 phÃºt tÃ¹y tá»‘c Ä‘á»™ máº¡ng.

### âš™ï¸ BÆ°á»›c 4: Cáº¥u hÃ¬nh (Optional)

Chá»‰nh sá»­a `config/config.yaml` náº¿u cáº§n:
```yaml
# Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n data
data:
  raw_path: "data/raw/your_data.xlsx"
  sheet_name: "YourSheet"

# Äiá»u chá»‰nh tham sá»‘ models
models:
  xgboost:
    n_estimators: [100, 200]  # Giáº£m Ä‘á»ƒ cháº¡y nhanh hÆ¡n
```

---

## ğŸ¯ CÃ¡ch cháº¡y Pipeline (Running the Pipeline)

### 1ï¸âƒ£ **Mode: EDA (Exploratory Data Analysis)**

PhÃ¢n tÃ­ch dá»¯ liá»‡u thÃ´, táº¡o cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan.

```powershell
python main.py --mode eda
```

**Output:**
- `artifacts/experiments/<run_id>/figures/eda/`
  - `missing_values.png` - Biá»ƒu Ä‘á»“ missing values
  - `correlation_matrix.png` - Ma tráº­n tÆ°Æ¡ng quan
  - `numerical_distributions.png` - PhÃ¢n phá»‘i cÃ¡c biáº¿n sá»‘
  - `target_distribution.png` - PhÃ¢n phá»‘i target (Churn)
  - `outliers_boxplot.png` - Boxplot phÃ¡t hiá»‡n outliers

**Use case:** Hiá»ƒu dá»¯ liá»‡u trÆ°á»›c khi preprocessing

---

### 2ï¸âƒ£ **Mode: Preprocess (Data Preprocessing)**

LÃ m sáº¡ch, split vÃ  transform dá»¯ liá»‡u.

```powershell
python main.py --mode preprocess
```

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**
1. Load raw data tá»« Excel
2. Clean data (remove duplicates, standardize)
3. Split train/test (80/20, stratified)
4. Fit transformer trÃªn train set
5. Transform cáº£ train vÃ  test set

**Output:**
- `data/processed/E Commerce Dataset_cleaned.parquet`
- `data/train_test/E Commerce Dataset_train.parquet`
- `data/train_test/E Commerce Dataset_test.parquet`
- `artifacts/experiments/<run_id>/data/` (snapshot)

**Use case:** Chuáº©n bá»‹ dá»¯ liá»‡u sáºµn sÃ ng cho training

---

### 3ï¸âƒ£ **Mode: Train (Model Training)**

Train models vá»›i dá»¯ liá»‡u Ä‘Ã£ preprocess.

#### A. Train má»™t model cá»¥ thá»ƒ (khÃ´ng optimize)

```powershell
python main.py --mode train --model xgboost
```

#### B. Train má»™t model vá»›i hyperparameter tuning

```powershell
python main.py --mode train --model xgboost --optimize
```

#### C. Train táº¥t cáº£ models

```powershell
python main.py --mode train --model all
```

#### D. Train táº¥t cáº£ models + optimize

```powershell
python main.py --mode train --model all --optimize
```

**Models há»— trá»£:**
- `logistic_regression` - Baseline model
- `svm` - Support Vector Machine
- `decision_tree` - Decision Tree
- `random_forest` - Random Forest Ensemble
- `xgboost` - XGBoost (thÆ°á»ng tá»‘t nháº¥t)
- `adaboost` - AdaBoost Ensemble
- `all` - Train táº¥t cáº£ models trÃªn

**Output:**
- `artifacts/experiments/<run_id>/models/xgboost.joblib` (best model)
- `artifacts/experiments/<run_id>/models/transformer.joblib` (cáº§n cho inference)
- `artifacts/experiments/<run_id>/metrics.json`
- `artifacts/model_registry/xgboost_v1_<timestamp>.joblib` (production model)

**Use case:** Training vÃ  tÃ¬m model tá»‘t nháº¥t

---

### 4ï¸âƒ£ **Mode: Visualize (Visualization Only)**

Cháº¡y quick training (khÃ´ng optimize) vÃ  táº¡o visualizations.

```powershell
python main.py --mode visualize --model xgboost
```

**Output:**
- `artifacts/experiments/<run_id>/figures/evaluation/`
  - `confusion_matrix_xgboost.png`
  - `roc_curve.png`
  - `feature_importance.png`
  - `model_comparison.png`
  - `shap_summary.png` (náº¿u enabled)

**Use case:** Kiá»ƒm tra nhanh performance vÃ  feature importance

---

### 5ï¸âƒ£ **Mode: Full (End-to-End Pipeline)** â­ Khuyáº¿n nghá»‹

Cháº¡y toÃ n bá»™ pipeline tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i.

```powershell
# Full pipeline vá»›i model cá»¥ thá»ƒ + optimize
python main.py --mode full --model xgboost --optimize

# Full pipeline vá»›i táº¥t cáº£ models + optimize
python main.py --mode full --model all --optimize

# Full pipeline nhanh (khÃ´ng optimize)
python main.py --mode full --model xgboost
```

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**
1. **EDA** - PhÃ¢n tÃ­ch dá»¯ liá»‡u thÃ´
2. **Preprocess** - Clean, split, transform
3. **Train** - Training models (vá»›i/khÃ´ng tuning)
4. **Visualize** - Táº¡o táº¥t cáº£ visualizations
5. **MLOps** - Log, registry, monitoring

**Output:** Äáº§y Ä‘á»§ táº¥t cáº£ outputs tá»« cÃ¡c modes trÃªn

**Use case:** Production pipeline hoÃ n chá»‰nh

---

### ğŸ”§ Tham sá»‘ CLI (Command-Line Arguments)

| Argument | MÃ´ táº£ | Máº·c Ä‘á»‹nh | VÃ­ dá»¥ |
|----------|-------|----------|-------|
| `--mode` | Cháº¿ Ä‘á»™ cháº¡y | `full` | `eda`, `preprocess`, `train`, `visualize`, `full` |
| `--model` | Model cá»¥ thá»ƒ | `all` | `xgboost`, `random_forest`, `logistic_regression` |
| `--optimize` | Báº­t hyperparameter tuning | `False` | `--optimize` |
| `--data` | ÄÆ°á»ng dáº«n data (override config) | `None` | `--data data/raw/new_data.xlsx` |
| `--config` | ÄÆ°á»ng dáº«n config file | `config/config.yaml` | `--config config/custom.yaml` |

### ğŸ“ VÃ­ dá»¥ thá»±c táº¿

```powershell
# 1. KhÃ¡m phÃ¡ dá»¯ liá»‡u má»›i
python main.py --mode eda --data "data/raw/new_customers.xlsx"

# 2. Train XGBoost vá»›i tuning cho production
python main.py --mode full --model xgboost --optimize

# 3. So sÃ¡nh táº¥t cáº£ models (khÃ´ng tuning - nhanh)
python main.py --mode train --model all

# 4. Cháº¡y vá»›i config tÃ¹y chá»‰nh
python main.py --mode full --config config/production.yaml --optimize

# 5. Debug: Chá»‰ visualize káº¿t quáº£
python main.py --mode visualize --model random_forest
```

---

## ğŸ§ª Testing (Kiá»ƒm thá»­)

### ğŸ“Š Test Coverage

Há»‡ thá»‘ng cÃ³ **77 unit tests** Ä‘Æ°á»£c tá»• chá»©c theo cáº¥u trÃºc module tÆ°Æ¡ng á»©ng vá»›i `src/`:

| Module Test | Sá»‘ Tests | MÃ´ táº£ |
|-------------|----------|-------|
| `test_data/test_preprocessor.py` | 8 | Tests cho DataPreprocessor (clean, split) |
| `test_data/test_transformer.py` | 12 | Tests cho DataTransformer (impute, encode, scale) |
| `test_models/test_trainer.py` | 13 | Tests cho ModelTrainer (train, evaluate, save) |
| `test_models/test_optimizer.py` | 6 | Tests cho ModelOptimizer (GridSearch, RandomizedSearch) |
| `test_models/test_evaluator.py` | 9 | Tests cho ModelEvaluator (metrics, confusion matrix) |
| `test_ops/test_dataops.py` | 12 | Tests cho DataValidator, DataVersioning |
| `test_ops/test_mlops.py` | 19 | Tests cho ExperimentTracker, ModelRegistry, ModelMonitor |
| `test_visualization/test_eda_plots.py` | 8 | Tests cho EDAVisualizer |
| `test_visualization/test_evaluate_plots.py` | 9 | Tests cho EvaluateVisualizer |
| `test_utils.py` | 14 | Tests cho utility functions |
| `test_pipeline.py` | 5 | Tests cho Pipeline orchestrator |

### ğŸƒ CÃ¡c cÃ¡ch cháº¡y Tests

```powershell
# Cháº¡y táº¥t cáº£ tests
pytest

# Cháº¡y vá»›i verbose output
pytest -v

# Cháº¡y theo module cá»¥ thá»ƒ
pytest tests/test_data/                     # Táº¥t cáº£ tests cho data module
pytest tests/test_models/                   # Táº¥t cáº£ tests cho models module
pytest tests/test_ops/                      # Táº¥t cáº£ tests cho ops module
pytest tests/test_visualization/            # Táº¥t cáº£ tests cho visualization module

# Cháº¡y file test cá»¥ thá»ƒ
pytest tests/test_data/test_preprocessor.py
pytest tests/test_models/test_trainer.py

# Cháº¡y test case cá»¥ thá»ƒ
pytest tests/test_data/test_preprocessor.py::TestDataPreprocessor::test_clean_data_removes_duplicates

# Cháº¡y vá»›i coverage
pytest --cov=src --cov-report=term-missing

# Coverage HTML report
pytest --cov=src --cov-report=html
# Sau Ä‘Ã³ má»Ÿ: htmlcov/index.html

# Cháº¡y tests matching pattern
pytest -k "transformer"

# Stop khi fail Ä‘áº§u tiÃªn
pytest -x

# Cháº¡y song song (nhanh hÆ¡n)
pip install pytest-xdist
pytest -n auto
```

**Coverage hiá»‡n táº¡i:** 93% (Target: â‰¥90%) âœ…

---

## ğŸ”„ Workflow thá»±c táº¿ (Real-world Workflow)

### Scenario 1: KhÃ¡m phÃ¡ dá»¯ liá»‡u má»›i

```powershell
# 1. Clone vÃ  setup
git clone https://github.com/civi0411/Churn_Analys_and_Prediction.git
cd Churn_Analys_and_Prediction
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

# 2. Äáº·t file data má»›i vÃ o thÆ° má»¥c
# Copy your_data.xlsx â†’ data/raw/

# 3. EDA Ä‘á»ƒ hiá»ƒu dá»¯ liá»‡u
python main.py --mode eda --data "data/raw/your_data.xlsx"

# 4. Xem káº¿t quáº£ trong artifacts/experiments/<run_id>/figures/eda/
```

### Scenario 2: Training model cho production

```powershell
# 1. Chá»‰nh config cho production
# Edit config/config.yaml:
#   - TÄƒng n_iter cho tuning
#   - Chá»n models phÃ¹ há»£p
#   - Báº­t monitoring

# 2. Cháº¡y full pipeline vá»›i optimize
python main.py --mode full --model xgboost --optimize

# 3. Kiá»ƒm tra káº¿t quáº£
# - artifacts/experiments/<run_id>/metrics.json
# - artifacts/model_registry/xgboost_v*.joblib

# 4. Deploy model
# Copy model tá»« registry ra production server
```

### Scenario 3: So sÃ¡nh nhiá»u models

```powershell
# 1. Train táº¥t cáº£ models vá»›i tuning
python main.py --mode train --model all --optimize

# 2. Xem model comparison chart
# artifacts/experiments/<run_id>/figures/evaluation/model_comparison.png

# 3. Select best model tá»« log
# Check logs hoáº·c metrics.json
```

### Scenario 4: Monitoring vÃ  retraining

```powershell
# 1. Kiá»ƒm tra performance log
# Review artifacts/monitoring/performance_log.csv

# 2. Náº¿u phÃ¡t hiá»‡n drift, retrain vá»›i data má»›i
python main.py --mode full --model xgboost --optimize --data "data/raw/new_batch.xlsx"

# 3. Compare metrics vá»›i version cÅ©
# So sÃ¡nh registry.json vÃ  performance_log.csv
```

---

## ğŸ› ï¸ Troubleshooting (Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p)

### âŒ Lá»—i: `FileNotFoundError: data/raw/E Commerce Dataset.xlsx`

**NguyÃªn nhÃ¢n:** File data khÃ´ng tá»“n táº¡i

**Giáº£i phÃ¡p:**
```powershell
# Kiá»ƒm tra file cÃ³ tá»“n táº¡i
ls data/raw/

# Náº¿u file cÃ³ tÃªn khÃ¡c, sá»­ dá»¥ng --data
python main.py --mode eda --data "data/raw/your_actual_filename.xlsx"

# Hoáº·c sá»­a config.yaml
# data:
#   raw_path: "data/raw/your_actual_filename.xlsx"
```

### âŒ Lá»—i: `KeyError: 'Churn'`

**NguyÃªn nhÃ¢n:** Cá»™t target khÃ´ng tá»“n táº¡i trong data

**Giáº£i phÃ¡p:**
```powershell
# Kiá»ƒm tra tÃªn cá»™t trong Excel/CSV
# Sá»­a config.yaml:
data:
  target_col: "YourActualTargetColumn"  # VÃ­ dá»¥: "Churned", "Exited", "Left"
```

### âŒ Lá»—i: SMOTE requires `n_neighbors <= n_samples`

**NguyÃªn nhÃ¢n:** Dá»¯ liá»‡u quÃ¡ Ã­t cho SMOTE

**Giáº£i phÃ¡p:**
```yaml
# Sá»­a config.yaml
preprocessing:
  use_smote: false  # Táº¯t SMOTE
  # Hoáº·c giáº£m k_neighbors
  k_neighbors: 3    # Thay vÃ¬ 5
```

### âŒ Lá»—i: `OutOfMemoryError` khi train

**NguyÃªn nhÃ¢n:** Model hoáº·c data quÃ¡ lá»›n

**Giáº£i phÃ¡p:**
```yaml
# Giáº£m complexity cá»§a models trong config.yaml
models:
  xgboost:
    n_estimators: [50, 100]      # Thay vÃ¬ [100, 300, 500]
    max_depth: [3, 5]            # Thay vÃ¬ [3, 5, 7]

# Hoáº·c giáº£m n_iter cho tuning
tuning:
  n_iter: 10                     # Thay vÃ¬ 20
```

### âŒ Lá»—i: Tests fail

**Giáº£i phÃ¡p:**
```powershell
# 1. Cháº¡y tests vá»›i verbose Ä‘á»ƒ xem lá»—i chi tiáº¿t
pytest -v -s

# 2. Cháº¡y test cá»¥ thá»ƒ bá»‹ fail
pytest tests/test_data/test_preprocessor.py::TestDataPreprocessor::test_clean_data_removes_duplicates -v

# 3. Check dependencies
pip install -r requirements.txt --upgrade

# 4. Clear cache vÃ  rerun
pytest --cache-clear
```

---

## ğŸ“ˆ Káº¿t quáº£ máº«u (Sample Results)

### Model Performance Comparison

| Model | F1-Score | ROC-AUC | Precision | Recall | Training Time |
|-------|----------|---------|-----------|--------|---------------|
| XGBoost | **0.9123** | **0.9456** | 0.8945 | 0.9312 | 45.2s |
| Random Forest | 0.8876 | 0.9234 | 0.8723 | 0.9034 | 32.1s |
| Logistic Regression | 0.8234 | 0.8756 | 0.8012 | 0.8467 | 2.3s |
| SVM | 0.8456 | 0.8923 | 0.8234 | 0.8689 | 78.5s |
| Decision Tree | 0.7989 | 0.8234 | 0.7756 | 0.8234 | 1.8s |
| AdaBoost | 0.8567 | 0.9012 | 0.8345 | 0.8801 | 28.4s |

> ğŸ† **Best Model:** XGBoost vá»›i F1-Score = 0.9123

### Feature Importance (Top 10)

```
1. DaySinceLastOrder        0.1823
2. CashbackAmount           0.1456
3. OrderCount               0.1234
4. Tenure                   0.1123
5. CouponUsed               0.0945
6. ComplainStatus           0.0876
7. OrderAmountHikeFromlastYear  0.0756
8. WarehouseToHome          0.0645
9. DaySinceLastOrder_Log    0.0534
10. SatisfactionScore       0.0423
```

---

## ğŸ¤ Contributing (ÄÃ³ng gÃ³p)

Contributions are welcome! Náº¿u báº¡n muá»‘n Ä‘Ã³ng gÃ³p:

1. Fork repository
2. Táº¡o branch má»›i: `git checkout -b feature/your-feature`
3. Commit changes: `git commit -m 'Add some feature'`
4. Push to branch: `git push origin feature/your-feature`
5. Táº¡o Pull Request

### Development Guidelines

- âœ… Viáº¿t tests cho code má»›i (coverage â‰¥ 90%)
- âœ… Follow PEP 8 style guide
- âœ… ThÃªm docstrings cho functions/classes
- âœ… Cáº­p nháº­t README náº¿u thÃªm features má»›i

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“ Contact & Support

- **Author:** [civi0411](https://github.com/civi0411)
- **Repository:** [Churn_Analys_and_Prediction](https://github.com/civi0411/Churn_Analys_and_Prediction)
- **Issues:** [GitHub Issues](https://github.com/civi0411/Churn_Analys_and_Prediction/issues)

---

<p align="center">
  <b>Made with â¤ï¸ by <a href="https://github.com/civi0411">civi0411</a></b><br>
  <i>Data Science â€¢ Machine Learning â€¢ MLOps</i>
</p>

