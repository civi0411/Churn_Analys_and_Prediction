# Customer Churn Analysis & Prediction

## Overview

Dá»± Ã¡n nÃ y khÃ´ng chá»‰ lÃ  má»™t bÃ i toÃ¡n phÃ¢n loáº¡i Machine Learning thÃ´ng thÆ°á»ng. ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng Software Engineering for Data Science hoÃ n chá»‰nh, giáº£i quyáº¿t bÃ i toÃ¡n dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng rá»i bá» (Customer Churn) cho lÄ©nh vá»±c ThÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ (E-Commerce).

> KhÃ¡c biá»‡t chÃ­nh: Thay vÃ¬ cháº¡y code trÃªn Jupyter Notebook rá»i ráº¡c, há»‡ thá»‘ng nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh má»™t Pipeline khÃ©p kÃ­n, cÃ³ kháº£ nÄƒng tÃ¡i sá»­ dá»¥ng (reproducible), dá»… dÃ ng má»Ÿ rá»™ng (scalable) vÃ  tÃ­ch há»£p sáºµn quy trÃ¬nh MLOps tá»± xÃ¢y dá»±ng (Custom MLOps).

### Business Value

| GiÃ¡ trá»‹ | MÃ´ táº£ |
|---------|-------|
| Screening | Nháº­n diá»‡n khÃ¡ch hÃ ng cÃ³ nguy cÆ¡ rá»i bá» vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao (F1-Score > 0.85) |
| Behavior Insights | Sá»­ dá»¥ng SHAP Ä‘á»ƒ giáº£i thÃ­ch lÃ½ do khÃ¡ch hÃ ng rá»i bá» |
| Cost Optimization | GiÃºp bá»™ pháº­n Marketing khoanh vÃ¹ng Ä‘Ãºng Ä‘á»‘i tÆ°á»£ng Ä‘á»ƒ gá»­i voucher giá»¯ chÃ¢n |
| Model Governance | Version tracking cho dá»¯ liá»‡u, model registry, monitoring vÃ  health check tá»± Ä‘á»™ng |

### Key Technical Features

- Modular Architecture: TÃ¡ch biá»‡t rÃµ rÃ ng giá»¯a Data, Model, Ops, Visualization
- Data Leakage Prevention: Fit trÃªn Train, Transform trÃªn Test - tuÃ¢n thá»§ nghiÃªm ngáº·t
- Multiple Models Support: LogisticRegression, SVM, DecisionTree, RandomForest, XGBoost, AdaBoost
- Automated Hyperparameter Tuning: RandomizedSearchCV vá»›i cross-validation
- Imbalanced Data Handling: SMOTE + Tomek Links Ä‘á»ƒ cÃ¢n báº±ng lá»›p Churn
- Experiment Tracking: LÆ°u trá»¯ tá»«ng run vá»›i snapshot config, metrics, models
- Model Registry: Quáº£n lÃ½ phiÃªn báº£n model production-ready
- Performance Monitoring: Health check tá»± Ä‘á»™ng, drift detection
- Explainability: SHAP values Ä‘á»ƒ giáº£i thÃ­ch quyáº¿t Ä‘á»‹nh cá»§a model

---

## System Architecture

### Pipeline Flow - Luá»“ng xá»­ lÃ½ End-to-End

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#e3f2fd','primaryTextColor':'#1565c0','primaryBorderColor':'#1976d2','lineColor':'#42a5f5','secondaryColor':'#fff3e0','tertiaryColor':'#e8f5e9'}}}%%
flowchart TB
    START(["ğŸ¬ START"])
    FINISH(["âœ¨ FINISH"])
    
    INPUT[("ğŸ“¥ RAW DATA<br/><b>E Commerce Dataset</b><br/>Excel Sheet: E Comm")]
    
    subgraph S1 ["<b>ğŸ“Š STAGE 1: EDA</b>"]
        direction TB
        B1["ğŸ“‚ Load Raw Data"]
        B2["ğŸ” Analyze Missing Values"]
        B3["ğŸ“ˆ Correlation Matrix"]
        B4["ğŸ“Š Distribution Plots"]
        B5["âš ï¸ Outlier Detection"]
        B1 ==> B2 ==> B3 ==> B4 ==> B5
    end

    subgraph S2 ["<b>ğŸ§¹ STAGE 2: PREPROCESSING</b>"]
        direction TB
        C1["ğŸ”§ <b>Clean Data</b><br/>âœ“ Remove duplicates<br/>âœ“ Standardize columns<br/>âœ“ Fix errors"]
        C2["âœ… Validate Quality"]
        C3["âœ‚ï¸ <b>Stratified Split</b><br/>80% Train | 20% Test"]
        C1 ==> C2 ==> C3
    end

    subgraph S3 ["<b>âš™ï¸ STAGE 3: TRANSFORMATION</b>"]
        direction LR
        D1["ğŸ¯ <b>TRAIN SET</b>"]
        D2["ğŸ”¨ <b>FIT + TRANSFORM</b><br/>â€¢ Impute missing<br/>â€¢ Clip outliers<br/>â€¢ Feature engineering<br/>â€¢ Encoding & Scaling"]
        D3{{"ğŸ“¦ <b>LEARNED PARAMS</b><br/>Imputers | Bounds<br/>Encoders | Scaler"}}
        D4["ğŸ§ª <b>TEST SET</b>"]
        D5["ğŸ¨ <b>TRANSFORM ONLY</b><br/>Apply learned params"]
        
        D1 ==> D2
        D2 ==> D3
        D3 -.->|"store"| D2
        D4 ==> D5
        D3 ==>|"apply"| D5
    end

    subgraph S4 ["<b>ğŸ“ STAGE 4: TRAINING</b>"]
        direction TB
        E1["âš–ï¸ <b>Balance Classes</b><br/>SMOTE + Tomek"]
        E2["ğŸ¤– <b>Train 6 Models</b><br/>LR | SVM | DT<br/>RF | XGB | Ada"]
        E3["ğŸ” <b>Hyperparameter Tuning</b><br/>RandomizedSearchCV"]
        E4["ğŸ† <b>Select Best Model</b><br/>Based on F1-Score"]
        E1 ==> E2 ==> E3 ==> E4
    end

    subgraph S5 ["<b>ğŸ“ˆ STAGE 5: EVALUATION</b>"]
        direction TB
        F1["ğŸ“Š Confusion Matrix"]
        F2["ğŸ“‰ ROC-AUC Curves"]
        F3["ğŸ¯ Feature Importance"]
        F4["ğŸ“‹ Model Comparison"]
        F5["ğŸ”¬ SHAP Explainability"]
        F1 ==> F2 ==> F3 ==> F4 ==> F5
    end

    subgraph S6 ["<b>ğŸ“¦ STAGE 6: MLOPS</b>"]
        direction TB
        G1["ğŸ“ Experiment Tracker"]
        G2["ğŸ—ƒï¸ Model Registry"]
        G3["ğŸ”– Data Versioning"]
        G4["ğŸ‘ï¸ Model Monitor"]
        G1 ==> G2 ==> G3 ==> G4
    end

    OUTPUT[("ğŸ’¾ <b>ARTIFACTS</b><br/>experiments/<br/>registry/<br/>monitoring/")]

    START ==> INPUT
    INPUT ==> S1
    S1 ==> S2
    S2 ==> S3
    S3 ==> S4
    S4 ==> S5
    S5 ==> S6
    S6 ==> OUTPUT
    OUTPUT ==> FINISH

    classDef startEnd fill:#4caf50,stroke:#2e7d32,stroke-width:3px,color:#fff,font-weight:bold
    classDef dataNode fill:#2196f3,stroke:#1565c0,stroke-width:3px,color:#fff,font-weight:bold
    classDef stage1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#e65100
    classDef stage2 fill:#e8f5e9,stroke:#43a047,stroke-width:2px,color:#2e7d32
    classDef stage3 fill:#f3e5f5,stroke:#8e24aa,stroke-width:2px,color:#6a1b9a
    classDef stage4 fill:#e0f2f1,stroke:#00897b,stroke-width:2px,color:#00695c
    classDef stage5 fill:#fff8e1,stroke:#fbc02d,stroke-width:2px,color:#f57f17
    classDef stage6 fill:#e8eaf6,stroke:#5e35b1,stroke-width:2px,color:#4527a0
    
    class START,FINISH startEnd
    class INPUT,OUTPUT dataNode
    class S1 stage1
    class S2 stage2
    class S3 stage3
    class S4 stage4
    class S5 stage5
    class S6 stage6
```

### NguyÃªn táº¯c chá»‘ng Data Leakage

> âš ï¸ **QUAN TRá»ŒNG**: Má»i thÃ´ng tin thá»‘ng kÃª (mean, std, IQR bounds, encoding mappings...) chá»‰ Ä‘Æ°á»£c há»c tá»« **Train Set**. Test Set chá»‰ Ä‘Æ°á»£c **Transform** vá»›i tham sá»‘ Ä‘Ã£ há»c - **KHÃ”NG BAO GIá»œ FIT Láº I!**

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#c8e6c9','secondaryColor':'#ffeb3b','tertiaryColor':'#ffcdd2'}}}%%
flowchart LR
    subgraph TRAIN ["<b>ğŸ¯ TRAIN SET</b><br/>(80% data)"]
        direction TB
        A["<b>1ï¸âƒ£ FIT</b><br/>ğŸ“š Learn Parameters<br/>from Training Data"]
        B["<b>2ï¸âƒ£ TRANSFORM</b><br/>ğŸ¨ Apply Parameters<br/>to Training Data"]
        A ===>|"fit"| B
    end

    PARAMS{{"<b>ğŸ“¦ LEARNED PARAMS</b><br/><br/>ğŸ“Š Imputer values<br/>(median/mode)<br/><br/>ğŸ“ Outlier bounds<br/>(Q1-1.5Ã—IQR, Q3+1.5Ã—IQR)<br/><br/>ğŸ”¤ Label encoders<br/>(category â†’ number)<br/><br/>âš–ï¸ Scaler params<br/>(mean, std)<br/><br/>âœ… Feature mask<br/>(selected features)"}}
    
    subgraph TEST ["<b>ğŸ§ª TEST SET</b><br/>(20% data)"]
        direction TB
        D["<b>3ï¸âƒ£ TRANSFORM ONLY</b><br/>ğŸ¨ Apply Parameters<br/>â›” NO FITTING!"]
    end
    
    B ==>|"<b>store</b>"| PARAMS
    PARAMS ==>|"<b>apply frozen</b>"| D
    
    WARNING["âš ï¸ <b>NO DATA LEAKAGE!</b><br/>Test never influences<br/>training parameters"]
    D -.->|"guarantee"| WARNING

    classDef trainStyle fill:#c8e6c9,stroke:#388e3c,stroke-width:3px,color:#1b5e20,font-weight:bold
    classDef paramStyle fill:#fff9c4,stroke:#f9a825,stroke-width:3px,color:#f57f17,font-weight:bold
    classDef testStyle fill:#ffcdd2,stroke:#e53935,stroke-width:3px,color:#c62828,font-weight:bold
    classDef warnStyle fill:#ff5252,stroke:#d32f2f,stroke-width:3px,color:#fff,font-weight:bold
    
    class TRAIN trainStyle
    class PARAMS paramStyle
    class TEST testStyle
    class WARNING warnStyle
```

### Kiáº¿n trÃºc module (Module Architecture)

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'fontSize':'14px'}}}%%
graph TB
    subgraph ENTRY ["<b>ğŸšª ENTRY POINT</b>"]
        MAIN["<b>ğŸ“„ main.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ® CLI Interface<br/>ğŸ“‹ Argument Parser<br/>ğŸš€ Launch Pipeline"]
    end
    
    subgraph PIPELINE ["<b>ğŸ”„ PIPELINE ORCHESTRATOR</b>"]
        PIPE["<b>ğŸ“„ pipeline.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ¬ run_eda()<br/>ğŸ§¹ run_preprocessing()<br/>ğŸ“ run_training()<br/>ğŸ“Š run_visualization()<br/>âš™ï¸ Coordinate all stages"]
    end

    subgraph DATA ["<b>ğŸ“Š DATA MODULE</b><br/>(src/data/)"]
        PREP["<b>preprocessor.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“‚ load_data()<br/>ğŸ§¹ clean_data()<br/>âœ‚ï¸ split_data()"]
        TRANS["<b>transformer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ”¨ fit_transform()<br/>ğŸ¨ transform()<br/>âš–ï¸ get_resampler()"]
    end
    
    subgraph MODELS ["<b>ğŸ¤– MODELS MODULE</b><br/>(src/models/)"]
        TRAIN["<b>trainer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“ train_model()<br/>ğŸ”„ train_all_models()<br/>ğŸ“Š evaluate()"]
        OPT["<b>optimizer.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ” optimize_params()<br/>ğŸ¯ grid_search()<br/>ğŸ“ˆ RandomizedSearch"]
        EVAL["<b>evaluator.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š calculate_metrics()<br/>ğŸ“‹ confusion_matrix()<br/>ğŸ“ˆ roc_auc_score()"]
    end
    
    subgraph VIZ ["<b>ğŸ“ˆ VISUALIZATION MODULE</b><br/>(src/visualization/)"]
        EDA["<b>eda_plots.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š missing_values()<br/>ğŸ“‰ correlation_matrix()<br/>ğŸ“ˆ distributions()"]
        EVIZ["<b>evaluate_plots.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“Š confusion_matrix()<br/>ğŸ“‰ roc_curve()<br/>ğŸ“ˆ feature_importance()"]
    end
    
    subgraph OPS ["<b>âš¡ OPS MODULE</b><br/>(src/ops/)"]
        DOPS["<b>dataops.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>âœ… DataValidator<br/>ğŸ”– DataVersioning<br/>ğŸ” Quality Checks"]
        MOPS["<b>mlops.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>ğŸ“ ExperimentTracker<br/>ğŸ—ƒï¸ ModelRegistry<br/>ğŸ‘ï¸ ModelMonitor<br/>ğŸ”¬ ModelExplainer"]
    end
    
    subgraph UTILS ["<b>ğŸ› ï¸ UTILITIES</b><br/>(src/)"]
        UTIL["<b>utils.py</b><br/>â•â•â•â•â•â•â•â•â•<br/>âš™ï¸ ConfigLoader<br/>ğŸ“ Logger<br/>ğŸ’¾ IOHandler<br/>ğŸ² set_random_seed()"]
    end

    MAIN ==>|"execute"| PIPE
    PIPE ==>|"orchestrate"| DATA
    PIPE ==>|"orchestrate"| MODELS
    PIPE ==>|"orchestrate"| VIZ
    PIPE ==>|"orchestrate"| OPS
    
    DATA -->|"use"| UTIL
    MODELS -->|"use"| UTIL
    VIZ -->|"use"| UTIL
    OPS -->|"use"| UTIL
    
    PREP -.->|"feeds into"| TRANS
    TRAIN -.->|"uses"| OPT
    TRAIN -.->|"uses"| EVAL

    classDef entryStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#0d47a1
    classDef pipeStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px,color:#4a148c
    classDef dataStyle fill:#e8f5e9,stroke:#388e3c,stroke-width:3px,color:#1b5e20
    classDef modelStyle fill:#fff3e0,stroke:#f57c00,stroke-width:3px,color:#e65100
    classDef vizStyle fill:#fce4ec,stroke:#c2185b,stroke-width:3px,color:#880e4f
    classDef opsStyle fill:#fff8e1,stroke:#fbc02d,stroke-width:3px,color:#f57f17
    classDef utilStyle fill:#eceff1,stroke:#546e7a,stroke-width:3px,color:#263238
    
    class ENTRY entryStyle
    class PIPELINE pipeStyle
    class DATA dataStyle
    class MODELS modelStyle
    class VIZ vizStyle
    class OPS opsStyle
    class UTILS utilStyle
```

---

## ğŸ“‚ Project Structure

```powershell
Churn_Analys_and_Prediction/
â”‚
â”œâ”€â”€ ğŸ“„ .gitignore                        # ğŸš« Git ignore rules
â”œâ”€â”€ ğŸ“„ main.py                           # ğŸšª Entry point chÃ­nh - CLI interface
â”œâ”€â”€ ğŸ“„ README.md                         # ğŸ“– Project documentation
â”œâ”€â”€ ğŸ“„ requirements.txt                  # ğŸ“¦ Python dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ config/                           # âš™ï¸ Cáº¤U HÃŒNH
â”‚   â””â”€â”€ ğŸ“„ config.yaml                   # File cáº¥u hÃ¬nh táº­p trung (paths, models, params)
â”‚
â”œâ”€â”€ ğŸ“‚ notebook/                         # ğŸ““ JUPYTER NOTEBOOKS
â”‚   â””â”€â”€ ğŸ“„ demo_pipeline.ipynb           # Demo luá»“ng cháº¡y cá»§a pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ src/                              # ğŸ’» MÃƒ NGUá»’N CHÃNH
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ pipeline.py                   # ğŸ”„ Orchestrator - Ä‘iá»u phá»‘i toÃ n bá»™ pipeline
â”‚   â”œâ”€â”€ ğŸ“„ utils.py                      # ğŸ› ï¸ Utilities (Logger, IO, ConfigLoader)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ data/                         # ğŸ“Š DATA PROCESSING MODULE
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ preprocessor.py           # Giai Ä‘oáº¡n 1: Load, Clean, Split (Stateless)
â”‚   â”‚   â””â”€â”€ ğŸ“„ transformer.py            # Giai Ä‘oáº¡n 2: Transform, Feature Eng (Stateful)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/                       # ğŸ¤– MODEL TRAINING MODULE
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ trainer.py                # Train logic, model selection
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ optimizer.py              # Hyperparameter tuning
â”‚   â”‚   â””â”€â”€ ğŸ“„ evaluator.py              # Metrics calculation logic
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ ops/                          # âš¡ MLOPS & DATAOPS MODULE
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ dataops/                  # Data Operations
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ drift_detector.py     # PhÃ¡t hiá»‡n trÃ´i dáº¡t dá»¯ liá»‡u (Data Drift)
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ validator.py          # Kiá»ƒm tra cháº¥t lÆ°á»£ng dá»¯ liá»‡u (Schema/Values)
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ versioning.py         # Quáº£n lÃ½ phiÃªn báº£n dá»¯ liá»‡u
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ mlops/                    # ML Operations
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ explainer.py          # Model Interpretability (SHAP/LIME)
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ monitoring.py         # Theo dÃµi hiá»‡u nÄƒng model
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ registry.py           # Quáº£n lÃ½, lÆ°u/táº£i model artifacts
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ tracking.py           # Experiment tracking
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“‚ report/                   # Reporting
â”‚   â”‚       â””â”€â”€ ğŸ“„ generator.py          # Sinh bÃ¡o cÃ¡o tá»± Ä‘á»™ng
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ visualization/                # ğŸ“ˆ VISUALIZATION MODULE
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ eda_plots.py              # Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch khÃ¡m phÃ¡ (EDA)
â”‚       â””â”€â”€ ğŸ“„ evaluate_plots.py         # Biá»ƒu Ä‘á»“ Ä‘Ã¡nh giÃ¡ model (ROC, Confusion Matrix)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                             # ğŸ’¾ Dá»® LIá»†U (LOCAL WORKSPACE)
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                          # Dá»¯ liá»‡u thÃ´ gá»‘c
â”‚   â”œâ”€â”€ ğŸ“‚ processed/                    # Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch
â”‚   â””â”€â”€ ğŸ“‚ train_test/                   # Dá»¯ liá»‡u Ä‘Ã£ split/transform Ä‘á»ƒ train
â”‚
â”œâ”€â”€ ğŸ“‚ artifacts/                        # ğŸ—„ï¸ OUTPUTS & ARCHIVE (Generated at runtime)
â”‚   â”œâ”€â”€ ğŸ“‚ experiments/                  # Logs chi tiáº¿t tá»«ng láº§n cháº¡y
â”‚   â”œâ”€â”€ ğŸ“‚ model_registry/               # CÃ¡c model Ä‘Ã£ Ä‘Ã³ng gÃ³i cho production
â”‚   â”œâ”€â”€ ğŸ“‚ monitoring/                   # Logs giÃ¡m sÃ¡t hiá»‡u nÄƒng
â”‚   â”œâ”€â”€ ğŸ“‚ versions/                     # Metadata cÃ¡c phiÃªn báº£n dá»¯ liá»‡u
â”‚   â”œâ”€â”€ ğŸ“‚ figures/                      # HÃ¬nh áº£nh biá»ƒu Ä‘á»“ má»›i nháº¥t
â”‚   â””â”€â”€ ğŸ“‚ logs/                         # System logs
â”‚
â””â”€â”€ ğŸ“‚ tests/                            # ğŸ§ª TESTING SUITE (Pytest)
    â”œâ”€â”€ ğŸ“„ conftest.py                   # Fixtures config
    â”œâ”€â”€ ğŸ“„ test_pipeline.py              # Integration tests
    â”œâ”€â”€ ğŸ“„ test_utils.py                 # Unit tests cho utils
    â”œâ”€â”€ ğŸ“‚ test_data/                    # Tests cho data processing
    â”œâ”€â”€ ğŸ“‚ test_models/                  # Tests cho model logic
    â”œâ”€â”€ ğŸ“‚ test_ops/                     # Tests cho MLOps/DataOps components
    â””â”€â”€ ğŸ“‚ test_visualization/           # Tests cho plotting functions
```


## âš™ï¸ Cáº¥u hÃ¬nh há»‡ thá»‘ng (Configuration)

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c táº­p trung trong `config/config.yaml`. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c sections chÃ­nh:

### ğŸ“Š Data Configuration
```yaml
data:
  target_col: "Churn"                        # DÃ¹ng cho train/test, transform, split
  date_col: "DaySinceLastOrder"                 # DÃ¹ng cho feature engineering
  base_dir: "data"                              # ÄÆ°á»ng dáº«n dá»¯ liá»‡u
  raw_path: "data/raw/E Commerce Dataset.xlsx"  # ÄÆ°á»ng dáº«n file gá»‘c
  sheet_name: "E Comm"                          # TÃªn sheet Excel
  processed_dir: "data/processed"               # ThÆ° má»¥c dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
  train_test_dir: "data/train_test"             # ThÆ° má»¥c train/test
  test_size: 0.2                                # Tá»· lá»‡ test (0.0 - 1.0)
  random_state: 42                              # Seed cho random
```

### ğŸ”§ Preprocessing Configuration
```yaml
preprocessing:
  clean:
    remove_duplicates: true          # XÃ³a dÃ²ng trÃ¹ng
    standardize_values: true         # Chuáº©n hÃ³a tÃªn cá»™t
  missing_strategy:
    numerical: "median"              # median hoáº·c mean
    categorical: "mode"              # mode hoáº·c unknown
  outlier_method: "iqr"              # iqr hoáº·c zscore
  outlier_threshold: 1.5             # NgÆ°á»¡ng cho iqr (thÆ°á»ng 1.5) hoáº·c zscore(thÆ°á»ng 3.0)
  scaler_type: "standard"            # standard, minmax, robust
  categorical_encoding: "label"      # Chá»‰ há»— trá»£ label
  create_features: true              # Táº¡o feature domain
  feature_selection: true            # Báº­t chá»n Ä‘áº·c trÆ°ng
  feature_selection_method: "f_classif" # f_classif hoáº·c mutual_info
  n_top_features: 15                 # Sá»‘ lÆ°á»£ng feature chá»n
  use_smote: true                    # Báº­t SMOTE
  k_neighbors: 5                     # Sá»‘ k cho SMOTE
  use_tomek: true                    # Báº­t SMOTETomek
```

### ğŸ¤– Models Configuration
```yaml
models:
  logistic_regression:
    C: [0.001, 0.01, 0.1, 1, 10]    # CÃ¡c giÃ¡ trá»‹ Ä‘á»ƒ tuning
    penalty: ["l2"]                 # Chá»‰ l2
    solver: ["lbfgs", "liblinear"]  # CÃ¡c solver
    max_iter: [1000]                 # Sá»‘ vÃ²ng láº·p

  svm:
    C: [0.1, 1, 10]                  # CÃ¡c giÃ¡ trá»‹ Ä‘á»ƒ tuning
    kernel: ["rbf", "linear"]        # kernel rbf hoáº·c linear
    gamma: ["scale", "auto"]         # gamma scale hoáº·c auto
    probability: [true]              # Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t

  decision_tree:
    max_depth: [6, 10, 16, null]     # Äá»™ sÃ¢u cÃ¢y
    min_samples_split: [2, 5, 10]    # Sá»‘ máº«u split
    min_samples_leaf: [1, 2, 4]      # Sá»‘ máº«u leaf

  random_forest:
    n_estimators: [50, 100, 200]     # Sá»‘ cÃ¢y
    max_depth: [10, 20, null]        # Äá»™ sÃ¢u cÃ¢y
    min_samples_split: [2, 5]        # Sá»‘ máº«u split
    min_samples_leaf: [1, 2]         # Sá»‘ máº«u leaf

  xgboost:
    n_estimators: [100, 300, 500]    # Sá»‘ cÃ¢y
    max_depth: [3, 5, 7]             # Äá»™ sÃ¢u cÃ¢y
    learning_rate: [0.01, 0.05, 0.1] # Tá»‘c Ä‘á»™ há»c
    eval_metric: ["logloss"]         # Chá»‰ logloss

  adaboost:
    n_estimators: [50, 100]          # Sá»‘ cÃ¢y
    learning_rate: [0.01, 0.1, 1.0]  # Tá»‘c Ä‘á»™ há»c
```

### ğŸ” Tuning Configuration
```yaml
tuning:
  method: "randomized"               # randomized hoáº·c grid
  cv_folds: 5                        # Sá»‘ fold cho CV
  cv_strategy: "stratified"          # Chiáº¿n lÆ°á»£c CV
  n_iter: 20                         # Sá»‘ láº§n láº·p
  scoring: "f1"                      # TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡
  n_jobs: -1                         # Sá»‘ job
```

### ğŸ“¦ Ops Configuration
```yaml
dataops:
  versions_dir: "artifacts/versions" # Quáº£n lÃ½ version dá»¯ liá»‡u
  drift_detection:
    enabled: true                    # Báº­t/táº¯t kiá»ƒm tra drift
    pvalue_threshold: 0.05           # NgÆ°á»¡ng kiá»ƒm tra drift
    max_drift_ratio: 0.2             # Tá»· lá»‡ drift tá»‘i Ä‘a
    abort_on_critical: true          # Há»§y náº¿u drift lá»›n
    sample_frac: 1.0                 # Tá»· lá»‡ sample
    max_rows: null                   # Giá»›i háº¡n sá»‘ dÃ²ng
  business_rules:
    persist: true                    # LÆ°u bÃ¡o cÃ¡o rules
    fail_on_violation: false         # Dá»«ng náº¿u vi pháº¡m rules

mlops:
  registry_dir: "artifacts/registry" # LÆ°u tráº¡ng thÃ¡i transformer, model

experiments:
  enabled: true                      # Báº­t/táº¯t tracking
  base_dir: "artifacts/experiments" # ThÆ° má»¥c tracking

monitoring:
  enabled: true                      # Báº­t/táº¯t monitoring
  base_dir: "artifacts/monitoring"  # ThÆ° má»¥c monitoring
  health_check:
    f1_min: 0.70                     # NgÆ°á»¡ng F1
    accuracy_min: 0.75               # NgÆ°á»¡ng accuracy
    drift_max: 0.10                  # NgÆ°á»¡ng drift

explainability:
  enabled: true                      # Báº­t/táº¯t SHAP
  methods: ["shap"]                 # Chá»‰ há»— trá»£ shap
  shap_samples: 100                  # Sá»‘ sample cho SHAP
```

---

## ğŸš€ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  sá»­ dá»¥ng (Installation & Usage)

### ğŸ“¥ BÆ°á»›c 1: Clone Repository

```powershell
git clone https://github.com/civi0411/Churn_Analys_and_Prediction.git
cd Churn_Analys_and_Prediction
```

### ğŸ BÆ°á»›c 2: Táº¡o Virtual Environment (Khuyáº¿n nghá»‹)

**Windows (PowerShell):**
```powershell
# Táº¡o virtual environment
python -m venv .venv

# KÃ­ch hoáº¡t virtual environment
.\.venv\Scripts\Activate.ps1

# Náº¿u gáº·p lá»—i ExecutionPolicy:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

**Linux/MacOS:**
```bash
# Táº¡o virtual environment
python3 -m venv .venv

# KÃ­ch hoáº¡t
source .venv/bin/activate
```

### ğŸ“¦ BÆ°á»›c 3: CÃ i Ä‘áº·t Dependencies

```powershell
# Upgrade pip
python -m pip install --upgrade pip

# CÃ i Ä‘áº·t táº¥t cáº£ packages
pip install -r requirements.txt

# Kiá»ƒm tra cÃ i Ä‘áº·t thÃ nh cÃ´ng
pip list
```

#### ğŸ“‹ Dependencies chi tiáº¿t (requirements.txt)

```
# --- Core Data Science (Xá»­ lÃ½ dá»¯ liá»‡u ná»n táº£ng) ---
numpy>=1.24.3           # TÃ­nh toÃ¡n ma tráº­n, sá»‘ há»c
pandas>=2.0.3           # Xá»­ lÃ½ DataFrame (Tá»‘i Æ°u bá»™ nhá»›)
scipy>=1.11.0           # Thá»‘ng kÃª khoa há»c (DÃ¹ng cho Drift Detection)
openpyxl>=3.1.2         # Engine Ä‘á»c file Excel (.xlsx)
pyarrow>=10.0.0         # Backend xá»­ lÃ½ dá»¯ liá»‡u lá»›n (Báº¯t buá»™c cho Parquet)
fastparquet>=2023.10.1  # Engine Ä‘á»c/ghi file Parquet tá»‘i Æ°u

# --- Machine Learning Models ---
scikit-learn>=1.3.0     # ThÆ° viá»‡n ML chÃ­nh (Pipeline, Metrics, RF)
xgboost>=2.0.0          # Model Gradient Boosting (Máº¡nh máº½)
imbalanced-learn>=0.11.0 # Há»— trá»£ SMOTE (Xá»­ lÃ½ dá»¯ liá»‡u máº¥t cÃ¢n báº±ng)

# --- Visualization (Trá»±c quan hÃ³a) ---
matplotlib>=3.7.2       # Váº½ biá»ƒu Ä‘á»“ cÆ¡ báº£n
seaborn>=0.12.2         # Váº½ biá»ƒu Ä‘á»“ thá»‘ng kÃª Ä‘áº¹p

# --- Explainability (Giáº£i thÃ­ch mÃ´ hÃ¬nh) ---
shap>=0.42.1            # Giáº£i thÃ­ch lÃ½ do Churn (Feature Importance)

# --- Utilities & System (Cáº¥u hÃ¬nh & Há»‡ thá»‘ng) ---
PyYAML>=6.0.1           # Äá»c file cáº¥u hÃ¬nh config.yaml
joblib>=1.3.2           # LÆ°u/Táº£i model (.pkl) tá»‘c Ä‘á»™ cao
tqdm>=4.66.1            # Thanh tiáº¿n trÃ¬nh (Loading bar)
typing-extensions>=4.7.1 # Há»— trá»£ Type Hinting

# --- Testing ---
pytest>=8.0.0           # Framework kiá»ƒm thá»­ (Testing framework)
pytest-cov>=6.0.0       # BÃ¡o cÃ¡o Ä‘á»™ bao phá»§ code (Coverage reporting)
```

### âš™ï¸ BÆ°á»›c 4: Cáº¥u hÃ¬nh (Optional)

Chá»‰nh sá»­a `config/config.yaml` náº¿u cáº§n:
```yaml
# Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n data
data:
  raw_path: "data/raw/your_data.xlsx"
  sheet_name: "YourSheet"

# Äiá»u chá»‰nh tham sá»‘ models
models:
  xgboost:
    n_estimators: [100, 200]  # Giáº£m Ä‘á»ƒ cháº¡y nhanh hÆ¡n
    max_depth: [3, 5]            # Thay vÃ¬ [3, 5, 7]
```

---

## ğŸ¯ CÃ¡ch cháº¡y Pipeline (Running the Pipeline)
#### ğŸ–¥ï¸ CLI Arguments (HÆ°á»›ng dáº«n cháº¡y dÃ²ng lá»‡nh)

Script `main.py` há»— trá»£ cÃ¡c tham sá»‘ sau Ä‘á»ƒ Ä‘iá»u khiá»ƒn luá»“ng cháº¡y cá»§a pipeline:

| Tham sá»‘ | Kiá»ƒu | Máº·c Ä‘á»‹nh | TÃ¹y chá»n (Choices) | MÃ´ táº£ chi tiáº¿t |
| :--- | :---: | :---: | :--- | :--- |
| **`--mode`** | `str` | `full` | `full`, `preprocess`, `train`, `eda`, `visualize`, `predict` | Cháº¿ Ä‘á»™ váº­n hÃ nh cá»§a Pipeline:<br>â€¢ `full`: Cháº¡y toÃ n bá»™ (Data -> Train -> Eval)<br>â€¢ `eda`: PhÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u<br>â€¢ `predict`: Dá»± Ä‘oÃ¡n trÃªn dá»¯ liá»‡u má»›i |
| **`--data`** | `str` | *Config* | *ÄÆ°á»ng dáº«n file* | ÄÆ°á»ng dáº«n file dá»¯ liá»‡u Ä‘áº§u vÃ o (Ghi Ä‘Ã¨ cáº¥u hÃ¬nh trong `config.yaml`).<br>Há»— trá»£ Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i hoáº·c tÆ°Æ¡ng Ä‘á»‘i. |
| **`--model`** | `str` | `all` | *TÃªn model* | Chá»‰ Ä‘á»‹nh model cá»¥ thá»ƒ Ä‘á»ƒ huáº¥n luyá»‡n/dá»± Ä‘oÃ¡n (VÃ­ dá»¥: `xgboost`, `random_forest`). |
| **`--optimize`** | `flag` | `False` | *(KhÃ´ng cÃ³)* | ThÃªm cá» nÃ y Ä‘á»ƒ báº­t cháº¿ Ä‘á»™ **Hyperparameter Tuning** (Tinh chá»‰nh tham sá»‘ mÃ´ hÃ¬nh). |
| **`--config`** | `str` | `config.yaml` | *ÄÆ°á»ng dáº«n file* | ÄÆ°á»ng dáº«n Ä‘áº¿n file cáº¥u hÃ¬nh tÃ¹y chá»‰nh (náº¿u cáº§n). |

### ğŸ’¡ Usage Examples (VÃ­ dá»¥)
**Mode: EDA (Exploratory Data Analysis)**

```powershell
# PhÃ¢n tÃ­ch dá»¯ liá»‡u thÃ´, táº¡o cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan.
python main.py --mode eda
```
**Mode: Preprocess (Data Preprocessing)**

```powershell
# LÃ m sáº¡ch, split vÃ  transform dá»¯ liá»‡u.
python main.py --mode preprocess
```
 **Mode: Train (Model Training)**
```powershell
## Train má»™t model cá»¥ thá»ƒ (khÃ´ng optimize)
python main.py --mode train 

# Train má»™t model vá»›i hyperparameter tuning
python main.py --mode train --model xgboost --optimize

# Train táº¥t cáº£ models
python main.py --mode train --model all

# Train táº¥t cáº£ models + optimize
python main.py --mode train --model all --optimize
```
  **Mode: Visualize (Evaluation)**
```powershell
# Cháº¡y quick training (khÃ´ng optimize) vÃ  táº¡o visualizations.
python main.py --mode visualize --model xgboost
```
**Mode: Full (End-to-End Pipeline)** â­ Khuyáº¿n nghá»‹

```powershell
# Full pipeline vá»›i model cá»¥ thá»ƒ + optimize
python main.py --mode full --model xgboost --optimize

# Full pipeline vá»›i táº¥t cáº£ models + optimize
python main.py --mode full --model all --optimize

# Full pipeline nhanh (khÃ´ng optimize)
python main.py --mode full --model xgboost
```
**Mode: Predict (Dá»± Ä‘oÃ¡n trÃªn dá»¯ liá»‡u má»›i)**
```powershell
python main.py --mode predict --data "data/raw/your_new_data.xlsx"  
# ! LÆ°u Ã½ pháº£i train dataset trÆ°á»›c khi thá»±c hiá»‡n predict máº«u data má»›i
```
Chá»©c nÄƒng nÃ y cho phÃ©p báº¡n sá»­ dá»¥ng model Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ dá»± Ä‘oÃ¡n trÃªn **dá»¯ liá»‡u má»›i** (chÆ°a tá»«ng train/test).

**Tham sá»‘:**
- `--data`: ÄÆ°á»ng dáº«n file dá»¯ liá»‡u Ä‘áº§u vÃ o (csv/xlsx/parquet). NÃªn lÃ  dá»¯ liá»‡u má»›i hoáº·c máº«u cáº§n inference.

**Output:**
- File káº¿t quáº£ dá»± Ä‘oÃ¡n sáº½ Ä‘Æ°á»£c lÆ°u táº¡i: `artifacts/predictions/<ten_file>_predicted.csv`
- Trong file káº¿t quáº£ sáº½ cÃ³ thÃªm cá»™t `prediction` (label dá»± Ä‘oÃ¡n)

**Best Practice:**
- **NÃªn** dÃ¹ng dá»¯ liá»‡u má»›i (chÆ°a tá»«ng train/test) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a model.
- **KhÃ´ng nÃªn** dÃ¹ng láº¡i dá»¯ liá»‡u Ä‘Ã£ train/test Ä‘á»ƒ trÃ¡nh data leakage.
- CÃ³ thá»ƒ dÃ¹ng sample nhá» Ä‘á»ƒ kiá»ƒm thá»­ ká»¹ thuáº­t, nhÆ°ng nÃªn lÃ  sample tá»« dá»¯ liá»‡u má»›i.

**Troubleshooting:**
- Náº¿u gáº·p lá»—i vá» cá»™t thiáº¿u, hÃ£y Ä‘áº£m báº£o file input cÃ³ Ä‘á»§ cÃ¡c cá»™t nhÆ° lÃºc train (trá»« cá»™t target).
- Náº¿u gáº·p lá»—i thÃ¬ xem thá»±c hiá»‡n train trÆ°á»›c vá»›i dataset máº«u rá»“i thá»±c hiá»‡n predict dÃ¢t má»›i nhÃ©


## ğŸ§ª Testing (Kiá»ƒm thá»­)

### ğŸ“Š Cáº¥u trÃºc Tests

Tests Ä‘Æ°á»£c tá»• chá»©c theo cáº¥u trÃºc module tÆ°Æ¡ng á»©ng vá»›i `src/`:

```powershell
tests/
â”œâ”€â”€ conftest.py                    # Pytest fixtures chung
â”œâ”€â”€ test_utils.py                  # Tests cho src/utils.py
â”œâ”€â”€ test_pipeline.py               # Tests cho src/pipeline.py
â”œâ”€â”€ test_data/
â”œâ”€â”€ test_models/
â”œâ”€â”€ test_ops/
â”‚   â”œâ”€â”€ test_dataops/           # DataValidator, DataVersioning
â”‚   â””â”€â”€ test_mlops/              # ExperimentTracker, ModelRegistry, ModelMonitor
â”œâ”€â”€ test_visualization/
```
### ğŸƒ CÃ¡ch cháº¡y Tests

```powershell
# Cháº¡y táº¥t cáº£ tests
pytest

# Cháº¡y module cá»¥ thá»ƒ
pytest tests/test_data/ -v                  # Data module
pytest tests/test_models/ -v                # Models module

# Cháº¡y file cá»¥ thá»ƒ
pytest tests/test_data/test_preprocessor.py -v

# Cháº¡y test case cá»¥ thá»ƒ
pytest tests/test_data/test_preprocessor.py::TestDataPreprocessor::test_clean_data -v
```
## ğŸ“– HÆ°á»›ng dáº«n Äá»c & PhÃ¢n tÃ­ch Output
Sau khi cháº¡y pipeline, toÃ n bá»™ káº¿t quáº£, log vÃ  model sáº½ Ä‘Æ°á»£c lÆ°u tá»± Ä‘á»™ng vÃ o thÆ° má»¥c `artifacts/`. DÆ°á»›i Ä‘Ã¢y lÃ  cáº¥u trÃºc tá»• chá»©c file Ä‘áº§u ra:

```powershell
artifacts/
â”œâ”€â”€ experiments/                        # LÆ°u trá»¯ káº¿t quáº£ tá»«ng láº§n cháº¡y (Run History)
â”‚   â”œâ”€â”€ 20251211_175911_FULL/           # VÃ­ dá»¥ má»™t Run huáº¥n luyá»‡n (Timestamp + Tag)
â”‚   â”‚   â”œâ”€â”€ data/                       # Dá»¯ liá»‡u snapshot dÃ¹ng cho run nÃ y
â”‚   â”‚   â”œâ”€â”€ figures/                    # Biá»ƒu Ä‘á»“ trá»±c quan hÃ³a (EDA & EVAL)
â”‚   â”‚   â”œâ”€â”€ models/                     # CÃ¡c file config vÃ  tham sá»‘ model
â”‚   â”‚   â”œâ”€â”€ config_snapshot.yaml        # Snapshot cáº¥u hÃ¬nh táº¡i thá»i Ä‘iá»ƒm cháº¡y
â”‚   â”‚   â”œâ”€â”€ full.log                    # Log riÃªng cá»§a run nÃ y (mode_name.log)
â”‚   â”‚   â”œâ”€â”€ metrics.json                # CÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ (Accuracy, F1...)
â”‚   â”‚   â”œâ”€â”€ params.json                 # CÃ¡c hyperparams Ä‘Ã£ dÃ¹ng
â”‚   â”‚   â””â”€â”€ report.md                   # BÃ¡o cÃ¡o tÃ³m táº¯t tá»± Ä‘á»™ng
â”‚   |â”€â”€ 20251211_180205_PREDICT/        # VÃ­ dá»¥ má»™t Run dá»± Ä‘oÃ¡n
â”‚   â””â”€â”€ experiments.csv                 # Quáº£n lÃ½ thÃ­ nghiá»‡m
â”œâ”€â”€ logs/                               # System Logs (Log há»‡ thá»‘ng/Debug)
â”‚   â”œâ”€â”€ MAIN_20251211_175911.log
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monitoring/                         
â”‚   â”œâ”€â”€ alerts_log.csv                  # Cáº£nh bÃ¡o data drift
â”‚   â””â”€â”€ performance_log.csv             # GiÃ¡m sÃ¡t hiá»‡u nÄƒng
â”œâ”€â”€ registry/                           # Kho chá»©a Model Production (Model Registry)
â”‚   â”œâ”€â”€ registry.json                   # File quáº£n lÃ½ phiÃªn báº£n model
â”‚   â”œâ”€â”€ transformer_state.joblib        # Pipeline xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â””â”€â”€ xgboost_v1_20251211_*.joblib    # File model Ä‘Ã£ huáº¥n luyá»‡n
â””â”€â”€ versions/
    â””â”€â”€ versions.json                   # Quáº£n lÃ½ version dá»¯ liá»‡u/code
```

### 1. ğŸ§ª ThÆ° má»¥c `experiments/` (Quan trá»ng nháº¥t)
ÄÃ¢y lÃ  nÆ¡i báº¡n kiá»ƒm tra káº¿t quáº£ huáº¥n luyá»‡n hoáº·c dá»± Ä‘oÃ¡n. Má»—i láº§n cháº¡y táº¡o ra má»™t thÆ° má»¥c con Ä‘á»‹nh dáº¡ng `YYYYMMDD_HHMMSS_[TAG]`.

* **`report.md` 
(BÃ¡o cÃ¡o tá»•ng há»£p nhanh táº¥t cáº£ tá»« EDA - TRAIN - MODEL - EVAL):**
    ÄÃ¢y lÃ  file tÃ³m táº¯t nhanh káº¿t quáº£ cháº¡y.
    > **ğŸ’¡ Máº¹o xem file:**
    > * **KhuyÃªn dÃ¹ng:** Má»Ÿ báº±ng **VSCode** vÃ  nháº¥n tá»• há»£p `Ctrl+Shift+V` Ä‘á»ƒ xem cháº¿ Ä‘á»™ Preview Ä‘áº¹p nháº¥t.
    > * **LÆ°u Ã½:** Náº¿u dÃ¹ng **PyCharm**, cháº¿ Ä‘á»™ preview máº·c Ä‘á»‹nh thÆ°á»ng hiá»ƒn thá»‹ khÃ´ng tá»‘t (bá»‹ vá»¡ layout). Báº¡n nÃªn cÃ i thÃªm plugin Markdown hoáº·c má»Ÿ báº±ng editor khÃ¡c.

* **`figures/`**: ThÆ° má»¥c chá»©a cÃ¡c file áº£nh biá»ƒu Ä‘á»“ `.png`.
    * *CÃ¡ch xem:* Double-click Ä‘á»ƒ má»Ÿ báº±ng trÃ¬nh xem áº£nh máº·c Ä‘á»‹nh, hoáº·c dÃ¹ng lá»‡nh `Invoke-Item` náº¿u Ä‘ang á»Ÿ PowerShell.

* **`metrics.json` / `params.json`**: Chá»©a cÃ¡c con sá»‘ chÃ­nh xÃ¡c vá» hiá»‡u nÄƒng vÃ  tham sá»‘.
    * *CÃ¡ch xem:* Má»Ÿ báº±ng VSCode, Notepad hoáº·c kÃ©o tháº£ vÃ o trÃ¬nh duyá»‡t web Ä‘á»ƒ xem cáº¥u trÃºc JSON.

* **Káº¿t quáº£ dá»± Ä‘oÃ¡n (`*_PREDICT` folders):**
    Náº¿u báº¡n cháº¡y pipeline dá»± Ä‘oÃ¡n, káº¿t quáº£ thÆ°á»ng náº±m trong file `experiments.csv`.
    * *CÃ¡ch xem:* Tá»‘t nháº¥t má»Ÿ báº±ng **Excel**. Náº¿u file quÃ¡ lá»›n, hÃ£y dÃ¹ng Python (Pandas) hoáº·c PowerShell Ä‘á»ƒ Ä‘á»c vÃ i dÃ²ng Ä‘áº§u (`Get-Content experiments.csv -Head 10`).

### 2. ğŸ­ ThÆ° má»¥c `registry/` (Model Registry)
NÆ¡i lÆ°u trá»¯ "tÃ i sáº£n" quan trá»ng nháº¥t: cÃ¡c model Ä‘Ã£ sáºµn sÃ ng hoáº·c Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng.

* **`registry.json`**: File quan trá»ng nháº¥t Ä‘á»ƒ há»‡ thá»‘ng biáº¿t model nÃ o Ä‘ang lÃ  **Production** (Ä‘ang cháº¡y thá»±c táº¿) hay **Staging**. Má»Ÿ file nÃ y báº±ng Text Editor Ä‘á»ƒ kiá»ƒm tra phiÃªn báº£n.
* **`*.joblib`**: CÃ¡c file model nhá»‹ phÃ¢n thá»±c táº¿. **KhÃ´ng sá»­a Ä‘á»•i thá»§ cÃ´ng** cÃ¡c file nÃ y.

### 3. ğŸ“ˆ ThÆ° má»¥c `monitoring/` (GiÃ¡m sÃ¡t)
DÃ¹ng Ä‘á»ƒ theo dÃµi sá»©c khá»e cá»§a mÃ´ hÃ¬nh theo thá»i gian.

* **`performance_log.csv`**: Lá»‹ch sá»­ Ä‘á»™ chÃ­nh xÃ¡c cá»§a model qua cÃ¡c láº§n Ä‘Ã¡nh giÃ¡.
* **`alerts_log.csv`**: Ghi láº¡i cÃ¡c cáº£nh bÃ¡o (vÃ­ dá»¥: Data Drift - dá»¯ liá»‡u bá»‹ thay Ä‘á»•i phÃ¢n phá»‘i).
    > **ğŸ’¡ Máº¹o:** CÃ¡c file nÃ y Ä‘á»‹nh dáº¡ng `.csv`, báº¡n nÃªn má»Ÿ báº±ng **Excel** Ä‘á»ƒ lá»c/sort dá»¯ liá»‡u dá»… dÃ ng, hoáº·c dÃ¹ng extension **Rainbow CSV** trong VSCode Ä‘á»ƒ xem nhanh.

### 4. ğŸ“ ThÆ° má»¥c `logs/`
Chá»©a log thÃ´ cá»§a toÃ n bá»™ quÃ¡ trÃ¬nh cháº¡y (`MAIN_*.log`). Chá»‰ cáº§n thiáº¿t khi báº¡n cáº§n **Debug** lá»—i (crash app, lá»—i thÆ° viá»‡n, lá»—i code).